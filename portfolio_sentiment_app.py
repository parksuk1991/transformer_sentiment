# Portfolio Sentiment Analysis with Transformer-based NLP
# Streamlit Application for Financial Sentiment Analysis

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import torch
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter
import re
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# í˜ì´ì§€ êµ¬ì„± ì„¤ì •
st.set_page_config(
    page_title="í¬íŠ¸í´ë¦¬ì˜¤ ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ ì •ì˜
st.markdown("""
    <style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    .positive {
        color: #28a745;
        font-weight: bold;
    }
    .negative {
        color: #dc3545;
        font-weight: bold;
    }
    .neutral {
        color: #6c757d;
        font-weight: bold;
    }
    </style>
    """, unsafe_allow_html=True)

# ======================== ëª¨ë¸ ìºì‹± ì„¤ì • ========================
@st.cache_resource
def load_sentiment_model():
    """
    FinBERT ëª¨ë¸ ë¡œë“œ (ê¸ˆìœµ í…ìŠ¤íŠ¸ì— ìµœì í™”ëœ Transformer ëª¨ë¸)
    FinBERTëŠ” BERTë¥¼ ê¸ˆìœµ ë°ì´í„°ë¡œ íŒŒì¸íŠœë‹í•œ ëª¨ë¸ë¡œ ë§¤ìš° ë†’ì€ ì •í™•ë„ ì œê³µ
    """
    try:
        # FinBERT ëª¨ë¸ ì‹œë„ (ê¸ˆìœµ ë„ë©”ì¸ ìµœì í™”)
        model_name = "ProsusAI/finbert"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        sentiment_pipeline = pipeline("sentiment-analysis", 
                                     model=model, 
                                     tokenizer=tokenizer,
                                     device=0 if torch.cuda.is_available() else -1)
        return sentiment_pipeline, "FinBERT (ê¸ˆìœµ ìµœì í™”)"
    except Exception as e:
        # í´ë°±: í‘œì¤€ BERT ëª¨ë¸
        try:
            sentiment_pipeline = pipeline("sentiment-analysis",
                                         model="distilbert-base-uncased-finetuned-sst-2-english",
                                         device=0 if torch.cuda.is_available() else -1)
            return sentiment_pipeline, "DistilBERT (ì¼ë°˜ ê°ì •ë¶„ì„)"
        except:
            # ìµœì¢… í´ë°±
            sentiment_pipeline = pipeline("sentiment-analysis",
                                         device=0 if torch.cuda.is_available() else -1)
            return sentiment_pipeline, "ê¸°ë³¸ Transformer ëª¨ë¸"

@st.cache_resource
def load_zero_shot_model():
    """
    Zero-shot classification ëª¨ë¸ ë¡œë“œ (ê¸ˆìœµ íŠ¹ì • ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜)
    """
    classifier = pipeline("zero-shot-classification",
                         model="facebook/bart-large-mnli",
                         device=0 if torch.cuda.is_available() else -1)
    return classifier

# ======================== ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ ========================

def preprocess_text(text):
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
    # HTML íƒœê·¸ ì œê±°
    text = re.sub(r'<[^>]+>', '', text)
    # URL ì œê±°
    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
    # íŠ¹ìˆ˜ ë¬¸ì ì •ë¦¬
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def chunk_text(text, max_length=512):
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í•  (ëª¨ë¸ í† í° ì œí•œ ëŒ€ì‘)"""
    sentences = re.split(r'[.!?]+', text)
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
        
        if len(current_chunk) + len(sentence) < max_length:
            current_chunk += sentence + ". "
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = sentence + ". "
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks if chunks else [text[:max_length]]

def analyze_sentiment_batch(texts, sentiment_pipeline, max_batch_size=32):
    """ë°°ì¹˜ ë‹¨ìœ„ ê°ì • ë¶„ì„"""
    all_sentiments = []
    all_scores = []
    
    for text in texts:
        if not text or len(text.strip()) == 0:
            all_sentiments.append("NEUTRAL")
            all_scores.append(0.0)
            continue
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        text = preprocess_text(text)
        
        # ê¸´ í…ìŠ¤íŠ¸ëŠ” ì²­í‚¹
        chunks = chunk_text(text, max_length=512)
        
        chunk_results = []
        for chunk in chunks:
            try:
                result = sentiment_pipeline(chunk, truncation=True, max_length=512)
                chunk_results.append(result)
            except Exception as e:
                st.warning(f"ì²­í¬ ë¶„ì„ ì˜¤ë¥˜: {e}")
                continue
        
        # ì²­í¬ ê²°ê³¼ ì§‘ê³„
        if chunk_results:
            positive_score = sum(1 for r in chunk_results if r[0]['label'] in ['POSITIVE', 'positive'])
            negative_score = sum(1 for r in chunk_results if r[0]['label'] in ['NEGATIVE', 'negative'])
            neutral_score = len(chunk_results) - positive_score - negative_score
            
            scores = [r[0]['score'] for r in chunk_results]
            avg_score = np.mean(scores)
            
            # ìµœì¢… ê°ì • ê²°ì •
            if positive_score > negative_score and positive_score > neutral_score:
                sentiment = "POSITIVE"
                final_score = avg_score
            elif negative_score > positive_score and negative_score > neutral_score:
                sentiment = "NEGATIVE"
                final_score = -avg_score
            else:
                sentiment = "NEUTRAL"
                final_score = 0.0
            
            all_sentiments.append(sentiment)
            all_scores.append(final_score)
        else:
            all_sentiments.append("NEUTRAL")
            all_scores.append(0.0)
    
    return all_sentiments, all_scores

def extract_keywords(text, n_words=10):
    """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ"""
    # ì „ì²˜ë¦¬
    text = preprocess_text(text.lower())
    
    # ë¶ˆìš©ì–´ ì œê±°
    stop_words = {
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
        'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
        'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
        'should', 'may', 'might', 'must', 'can', 'that', 'this', 'as', 'if',
        'it', 'its', 'which', 'who', 'what', 'when', 'where', 'why', 'how',
        'all', 'each', 'every', 'both', 'either', 'neither', 'such', 'same',
        'so', 'than', 'then', 'they', 'them', 'their', 'we', 'us', 'our',
        'you', 'your', 'he', 'him', 'his', 'she', 'her', 'hers', 'i', 'me', 'my', 'mine'
    }
    
    # ë‹¨ì–´ ì¶”ì¶œ ë° í•„í„°ë§
    words = re.findall(r'\b[a-z]{3,}\b', text)
    filtered_words = [w for w in words if w not in stop_words and len(w) > 2]
    
    # ë¹ˆë„ ê³„ì‚°
    word_freq = Counter(filtered_words)
    return word_freq.most_common(n_words)

def calculate_sentiment_metrics(df):
    """ê°ì • ë¶„ì„ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    sentiment_counts = df['Sentiment'].value_counts()
    
    metrics = {
        'total_documents': len(df),
        'positive_count': sentiment_counts.get('POSITIVE', 0),
        'negative_count': sentiment_counts.get('NEGATIVE', 0),
        'neutral_count': sentiment_counts.get('NEUTRAL', 0),
        'positive_ratio': sentiment_counts.get('POSITIVE', 0) / len(df) * 100,
        'negative_ratio': sentiment_counts.get('NEGATIVE', 0) / len(df) * 100,
        'neutral_ratio': sentiment_counts.get('NEUTRAL', 0) / len(df) * 100,
        'avg_sentiment_score': df['Sentiment_Score'].mean(),
        'sentiment_volatility': df['Sentiment_Score'].std(),
    }
    
    return metrics

def calculate_equity_ranking(sentiment_df):
    """ì¢…ëª©ë³„ ìˆœìœ„ ê³„ì‚° (í¬íŠ¸í´ë¦¬ì˜¤ ì„ í˜¸ë„ ì ìˆ˜)"""
    equity_stats = sentiment_df.groupby('Equity').agg({
        'Sentiment': 'count',
        'Sentiment_Score': ['mean', 'std', 'max', 'min'],
        'Document Title': 'count'
    }).round(4)
    
    equity_stats.columns = ['Total_Docs', 'Avg_Score', 'Score_Std', 'Max_Score', 'Min_Score', 'Reports']
    
    # ì¢…í•© ì ìˆ˜ ê³„ì‚° (ì—¬ëŸ¬ ì§€í‘œ ê°€ì¤‘í•©)
    equity_stats['Sentiment_Grade'] = equity_stats['Avg_Score'].apply(
        lambda x: 'A+' if x > 0.8 else ('A' if x > 0.6 else ('B+' if x > 0.4 else 
                  ('B' if x > 0.2 else ('C' if x > -0.2 else ('D' if x > -0.4 else 'F')))))
    )
    
    # ì¢…í•© ì ìˆ˜: í‰ê·  + ì¼ê´€ì„±(std ì—­ìˆ˜) + ìƒ˜í”Œ ìˆ˜ ì •ê·œí™”
    consistency_score = 1 / (1 + equity_stats['Score_Std'].fillna(0))
    document_weight = equity_stats['Total_Docs'] / equity_stats['Total_Docs'].max()
    
    equity_stats['Portfolio_Score'] = (
        equity_stats['Avg_Score'] * 0.5 + 
        consistency_score * 0.3 + 
        document_weight * 0.2
    )
    
    equity_stats['Investment_Preference'] = equity_stats['Portfolio_Score'].apply(
        lambda x: 'ê°•ë ¥ ì¶”ì²œ' if x > 0.6 else ('ì¶”ì²œ' if x > 0.3 else ('ì¤‘ë¦½' if x > -0.1 else 'íšŒí”¼')))
    
    return equity_stats.sort_values('Portfolio_Score', ascending=False)

# ======================== ì‹œê°í™” í•¨ìˆ˜ ========================

def plot_sentiment_distribution(df):
    """ê°ì • ë¶„í¬ ì‹œê°í™”"""
    sentiment_counts = df['Sentiment'].value_counts()
    
    fig = go.Figure(data=[
        go.Bar(
            x=sentiment_counts.index,
            y=sentiment_counts.values,
            marker=dict(
                color=['#28a745' if x == 'POSITIVE' else ('#dc3545' if x == 'NEGATIVE' else '#6c757d')
                       for x in sentiment_counts.index]
            ),
            text=sentiment_counts.values,
            textposition='auto',
        )
    ])
    
    fig.update_layout(
        title="ì „ì²´ ê°ì • ë¶„í¬",
        xaxis_title="ê°ì • ë¶„ë¥˜",
        yaxis_title="ë¬¸ì„œ ìˆ˜",
        template="plotly_white",
        height=400
    )
    
    return fig

def plot_equity_sentiment_heatmap(df):
    """ì¢…ëª©ë³„ ê°ì • ì ìˆ˜ íˆíŠ¸ë§µ"""
    pivot_data = df.pivot_table(
        values='Sentiment_Score',
        index='Equity',
        columns='Sentiment',
        aggfunc='count',
        fill_value=0
    )
    
    # ê°ì •ë³„ ì ìˆ˜ í‰ê· 
    pivot_scores = df.pivot_table(
        values='Sentiment_Score',
        index='Equity',
        aggfunc='mean'
    )
    
    fig = px.bar(
        pivot_scores.reset_index(),
        x='Equity',
        y='Sentiment_Score',
        color='Sentiment_Score',
        color_continuous_scale='RdYlGn',
        title="ì¢…ëª©ë³„ í‰ê·  ê°ì • ì ìˆ˜",
        labels={'Sentiment_Score': 'ê°ì • ì ìˆ˜'},
    )
    
    fig.update_layout(height=400, template="plotly_white")
    return fig

def plot_sentiment_timeline(df):
    """ì‹œê°„ëŒ€ë³„ ê°ì • ì¶”ì´"""
    df_time = df.copy()
    df_time['Date'] = pd.to_datetime(df_time['Date'], errors='coerce')
    df_time = df_time.dropna(subset=['Date'])
    
    if len(df_time) == 0:
        return None
    
    daily_sentiment = df_time.groupby(df_time['Date'].dt.date).agg({
        'Sentiment_Score': 'mean',
        'Document Title': 'count'
    }).reset_index()
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=daily_sentiment['Date'],
        y=daily_sentiment['Sentiment_Score'],
        mode='lines+markers',
        name='ê°ì • ì ìˆ˜',
        line=dict(color='#0066cc', width=2),
        marker=dict(size=8)
    ))
    
    fig.add_hline(y=0, line_dash="dash", line_color="gray", opacity=0.5)
    
    fig.update_layout(
        title="ì‹œê°„ëŒ€ë³„ ê°ì • ì¶”ì´",
        xaxis_title="ë‚ ì§œ",
        yaxis_title="ê°ì • ì ìˆ˜",
        template="plotly_white",
        height=400,
        hovermode='x unified'
    )
    
    return fig

def plot_wordcloud(text_data, sentiment_filter=None):
    """ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±"""
    if sentiment_filter:
        text_data = text_data[text_data['Sentiment'] == sentiment_filter]
    
    combined_text = ' '.join(text_data['Text'].astype(str).tolist())
    
    if not combined_text.strip():
        return None
    
    wordcloud = WordCloud(
        width=800,
        height=400,
        background_color='white',
        colormap='viridis',
        max_words=100
    ).generate(combined_text)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    
    return fig

def plot_equity_comparison(equity_ranking):
    """ì¢…ëª© ë¹„êµ ì°¨íŠ¸"""
    top_n = min(10, len(equity_ranking))
    top_equities = equity_ranking.head(top_n)
    
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=("í¬íŠ¸í´ë¦¬ì˜¤ ì ìˆ˜", "í‰ê·  ê°ì • ì ìˆ˜", "ì ìˆ˜ ì¼ê´€ì„± (ì—­ìˆ˜)", "ë¬¸ì„œ ìˆ˜"),
        specs=[[{}, {}], [{}, {}]]
    )
    
    # Portfolio Score
    fig.add_trace(
        go.Bar(
            x=top_equities.index,
            y=top_equities['Portfolio_Score'],
            name='í¬íŠ¸í´ë¦¬ì˜¤ ì ìˆ˜',
            marker_color='lightblue',
            showlegend=False
        ),
        row=1, col=1
    )
    
    # Average Score
    fig.add_trace(
        go.Bar(
            x=top_equities.index,
            y=top_equities['Avg_Score'],
            name='í‰ê·  ê°ì •',
            marker_color='lightgreen',
            showlegend=False
        ),
        row=1, col=2
    )
    
    # Consistency
    fig.add_trace(
        go.Bar(
            x=top_equities.index,
            y=1/(1+top_equities['Score_Std'].fillna(0)),
            name='ì¼ê´€ì„±',
            marker_color='lightyellow',
            showlegend=False
        ),
        row=2, col=1
    )
    
    # Document Count
    fig.add_trace(
        go.Bar(
            x=top_equities.index,
            y=top_equities['Total_Docs'],
            name='ë¬¸ì„œìˆ˜',
            marker_color='lightcoral',
            showlegend=False
        ),
        row=2, col=2
    )
    
    fig.update_layout(height=800, template="plotly_white", showlegend=False)
    return fig

# ======================== Streamlit ë©”ì¸ ì•± ========================

def main():
    st.title("ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤ ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ")
    st.markdown("Transformer ê¸°ë°˜ ìµœì‹  NLP ëª¨ë¸ì„ í™œìš©í•œ ê¸ˆìœµ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.markdown("## âš™ï¸ ì„¤ì •")
    
    uploaded_file = st.sidebar.file_uploader(
        "CSV íŒŒì¼ ì—…ë¡œë“œ",
        type=['csv'],
        help="Document Title, Date, Equity, 0-6 ì—´ì„ í¬í•¨í•œ CSV íŒŒì¼"
    )
    
    analyze_button = st.sidebar.button("ğŸ“ˆ ê°ì • ë¶„ì„ ì‹¤í–‰", key="analyze_main")
    
    if uploaded_file is not None:
        # íŒŒì¼ ë¡œë“œ
        df = pd.read_csv(uploaded_file)
        
        st.sidebar.success("âœ… íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
        st.sidebar.markdown("---")
        
        # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
        with st.sidebar.expander("ğŸ“‹ ë°ì´í„° ì •ë³´"):
            st.write(f"ì´ í–‰ ìˆ˜: {len(df)}")
            st.write(f"ì»¬ëŸ¼: {', '.join(df.columns.tolist())}")
        
        # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ í†µí•©
        text_columns = [col for col in df.columns if col not in ['Document Title', 'Date', 'Equity']]
        df['Text'] = df[text_columns].fillna('').agg(' '.join, axis=1)
        
        if analyze_button or 'analysis_complete' not in st.session_state:
            st.session_state.analysis_complete = False
            
            with st.spinner("ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘..."):
                sentiment_pipeline, model_name = load_sentiment_model()
            
            st.info(f"âœ… ëª¨ë¸: {model_name}")
            
            with st.spinner("â³ ê°ì • ë¶„ì„ ì§„í–‰ ì¤‘... (ì´ ê³¼ì •ì€ ë°ì´í„° í¬ê¸°ì— ë”°ë¼ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                texts = df['Text'].tolist()
                sentiments, scores = analyze_sentiment_batch(texts, sentiment_pipeline)
                
                df['Sentiment'] = sentiments
                df['Sentiment_Score'] = scores
                
                progress_bar.progress(100)
                status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
            
            st.session_state.analysis_complete = True
            st.session_state.analysis_df = df
        
        if st.session_state.analysis_complete:
            df = st.session_state.analysis_df
            
            st.success("âœ… ê°ì • ë¶„ì„ ì™„ë£Œ!")
            
            # ==================== ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ ====================
            st.markdown("---")
            st.subheader("ğŸ“Š ì£¼ìš” ë©”íŠ¸ë¦­")
            
            metrics = calculate_sentiment_metrics(df)
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "ê¸ì •ì  ë¬¸ì„œ",
                    f"{metrics['positive_count']}ê°œ",
                    f"{metrics['positive_ratio']:.1f}%",
                    delta_color="normal"
                )
            
            with col2:
                st.metric(
                    "ë¶€ì •ì  ë¬¸ì„œ",
                    f"{metrics['negative_count']}ê°œ",
                    f"{metrics['negative_ratio']:.1f}%",
                    delta_color="inverse"
                )
            
            with col3:
                st.metric(
                    "ì¤‘ë¦½ì  ë¬¸ì„œ",
                    f"{metrics['neutral_count']}ê°œ",
                    f"{metrics['neutral_ratio']:.1f}%"
                )
            
            with col4:
                st.metric(
                    "í‰ê·  ê°ì • ì ìˆ˜",
                    f"{metrics['avg_sentiment_score']:.3f}",
                    f"ë³€ë™ì„±: {metrics['sentiment_volatility']:.3f}"
                )
            
            # ==================== ì‹œê°í™” ====================
            st.markdown("---")
            st.subheader("ğŸ“ˆ ê°ì • ë¶„ì„ ì‹œê°í™”")
            
            tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
                "ê°ì • ë¶„í¬", "ì¢…ëª© ì ìˆ˜", "ì‹œê°„ëŒ€ ì¶”ì´", "ìƒìœ„ ì¢…ëª©", "ì›Œë“œí´ë¼ìš°ë“œ", "ìƒì„¸ ë¶„ì„"
            ])
            
            with tab1:
                st.plotly_chart(plot_sentiment_distribution(df), use_container_width=True)
            
            with tab2:
                st.plotly_chart(plot_equity_sentiment_heatmap(df), use_container_width=True)
            
            with tab3:
                timeline_fig = plot_sentiment_timeline(df)
                if timeline_fig:
                    st.plotly_chart(timeline_fig, use_container_width=True)
                else:
                    st.info("ë‚ ì§œ ì •ë³´ê°€ ì—†ì–´ ì‹œê°„ëŒ€ ì¶”ì´ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            with tab4:
                equity_ranking = calculate_equity_ranking(df)
                st.plotly_chart(plot_equity_comparison(equity_ranking), use_container_width=True)
            
            with tab5:
                sentiment_filter = st.radio(
                    "ê°ì • ì„ íƒ",
                    options=["ì „ì²´", "POSITIVE", "NEGATIVE", "NEUTRAL"],
                    horizontal=True
                )
                
                filter_value = None if sentiment_filter == "ì „ì²´" else sentiment_filter
                wordcloud_fig = plot_wordcloud(df, sentiment_filter=filter_value)
                
                if wordcloud_fig:
                    st.pyplot(wordcloud_fig, use_container_width=True)
                else:
                    st.warning("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            with tab6:
                st.markdown("### ğŸ“‹ ìƒì„¸ ë¶„ì„")
                
                # ì¢…ëª©ë³„ ìˆœìœ„
                equity_ranking = calculate_equity_ranking(df)
                
                st.markdown("#### ğŸ† ì¢…ëª© ìˆœìœ„ ë° í¬íŠ¸í´ë¦¬ì˜¤ í‰ê°€")
                
                # ì˜ˆìœ í…Œì´ë¸”ë¡œ í‘œì‹œ
                display_ranking = equity_ranking[['Total_Docs', 'Avg_Score', 'Score_Std', 
                                                  'Portfolio_Score', 'Sentiment_Grade', 
                                                  'Investment_Preference']].copy()
                display_ranking.columns = ['ë¬¸ì„œìˆ˜', 'í‰ê· ê°ì •', 'ì ìˆ˜í¸ì°¨', 'í¬íŠ¸í´ë¦¬ì˜¤ì ìˆ˜', 'ë“±ê¸‰', 'íˆ¬ìì„ í˜¸ë„']
                display_ranking = display_ranking.round(4)
                
                st.dataframe(
                    display_ranking,
                    use_container_width=True,
                    height=400
                )
                
                # ì¢…ëª©ë³„ í‚¤ì›Œë“œ
                st.markdown("#### ğŸ” ì¢…ëª©ë³„ ì£¼ìš” í‚¤ì›Œë“œ")
                
                equities = df['Equity'].unique()
                selected_equity = st.selectbox("ì¢…ëª© ì„ íƒ", equities)
                
                equity_data = df[df['Equity'] == selected_equity]
                keywords = extract_keywords(' '.join(equity_data['Text'].astype(str)), n_words=15)
                
                if keywords:
                    keyword_df = pd.DataFrame(keywords, columns=['í‚¤ì›Œë“œ', 'ë¹ˆë„'])
                    
                    fig = px.bar(
                        keyword_df,
                        x='ë¹ˆë„',
                        y='í‚¤ì›Œë“œ',
                        orientation='h',
                        title=f"{selected_equity} - ì£¼ìš” í‚¤ì›Œë“œ",
                        color='ë¹ˆë„',
                        color_continuous_scale='Viridis'
                    )
                    fig.update_layout(height=400)
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("ì¶”ì¶œí•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # ê°ì •ë³„ ë¶„ì„
                st.markdown("#### ğŸ’­ ê°ì • ë¶„ë¥˜ë³„ ìƒì„¸ í†µê³„")
                
                sentiment_detail = df.groupby(['Equity', 'Sentiment']).agg({
                    'Document Title': 'count',
                    'Sentiment_Score': ['mean', 'std']
                }).round(4)
                
                sentiment_detail.columns = ['ë¬¸ì„œìˆ˜', 'í‰ê· ì ìˆ˜', 'í‘œì¤€í¸ì°¨']
                st.dataframe(sentiment_detail, use_container_width=True)
            
            # ==================== ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ ====================
            st.markdown("---")
            st.subheader("ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
            
            # ë¶„ì„ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ
            result_csv = df[['Document Title', 'Date', 'Equity', 'Sentiment', 'Sentiment_Score']].to_csv(index=False)
            st.download_button(
                label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ (CSV)",
                data=result_csv,
                file_name=f"sentiment_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
            
            # ì¢…ëª© ìˆœìœ„ ë‹¤ìš´ë¡œë“œ
            ranking_csv = equity_ranking.to_csv()
            st.download_button(
                label="ğŸ“Š ì¢…ëª© ìˆœìœ„ ë° ì ìˆ˜ (CSV)",
                data=ranking_csv,
                file_name=f"equity_ranking_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )
    
    else:
        st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        
        st.markdown("---")
        st.subheader("ğŸ“ ì‚¬ìš© ë°©ë²•")
        st.markdown("""
        1. **íŒŒì¼ ì—…ë¡œë“œ**: CSV íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤
           - í•„ìˆ˜ ì—´: Document Title, Date, Equity
           - í…ìŠ¤íŠ¸ ì—´: 0, 1, 2, 3, 4, 5, 6 (ìë™ìœ¼ë¡œ í†µí•©ë©ë‹ˆë‹¤)
        
        2. **ë¶„ì„ ì‹¤í–‰**: "ê°ì • ë¶„ì„ ì‹¤í–‰" ë²„íŠ¼ì„ í´ë¦­í•©ë‹ˆë‹¤
           - ìµœì‹  Transformer ëª¨ë¸ (FinBERT) ì‚¬ìš©
           - ê¸ˆìœµ ë„ë©”ì¸ì— ìµœì í™”ëœ ê°ì • ë¶„ì„
        
        3. **ê²°ê³¼ í™•ì¸**: 
           - ğŸ“Š ê°ì • ë¶„í¬ ë° ì‹œê°í™”
           - ğŸ† ì¢…ëª©ë³„ ìˆœìœ„ ë° í¬íŠ¸í´ë¦¬ì˜¤ ì ìˆ˜
           - ğŸ” ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„
           - ğŸ’­ ê°ì •ë³„ ìƒì„¸ í†µê³„
        
        4. **ê²°ê³¼ ë‹¤ìš´ë¡œë“œ**: ë¶„ì„ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤
        """)
        
        st.markdown("---")
        st.subheader("ğŸ¤– ì‚¬ìš© ëª¨ë¸")
        st.markdown("""
        - **FinBERT**: BERTë¥¼ ê¸ˆìœµ í…ìŠ¤íŠ¸ë¡œ íŒŒì¸íŠœë‹í•œ ìµœì‹  ëª¨ë¸
        - **Zero-shot Classification**: ì‚¬ìš©ì ì •ì˜ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
        - **Word Cloud**: ê°ì •ë³„ ì£¼ìš” ë‹¨ì–´ ì‹œê°í™”
        
        ì´ ëª¨ë¸ë“¤ì€ NLTK, Vader ë“± ì „í†µì  ë°©ì‹ë³´ë‹¤ í›¨ì”¬ ë†’ì€ ì •í™•ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
        """)

if __name__ == "__main__":
    main()
