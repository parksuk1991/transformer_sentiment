# Portfolio Sentiment Analysis with Transformer-based NLP
# Streamlit Application for Financial Sentiment Analysis

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import torch
import shap
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter
import re
from datetime import datetime
import warnings
import os

warnings.filterwarnings('ignore')

os.environ['CURL_CA_BUNDLE'] = ''
os.environ['REQUESTS_CA_BUNDLE'] = ''

# í˜ì´ì§€ êµ¬ì„± ì„¤ì •
st.set_page_config(
    page_title="Sentiment Analysis",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    .positive {
        color: #28a745;
        font-weight: bold;
    }
    .negative {
        color: #dc3545;
        font-weight: bold;
    }
    .neutral {
        color: #6c757d;
        font-weight: bold;
    }
    .top-equity {
        font-size: 24px;
        font-weight: bold;
        color: #0066cc;
    }
    </style>
    """, unsafe_allow_html=True)

# ======================== ëª¨ë¸ ìºì‹± ì„¤ì • ========================
@st.cache_resource
def load_sentiment_model():
    """FinBERT ëª¨ë¸ ë¡œë“œ"""
    try:
        model_name = "ProsusAI/finbert"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        sentiment_pipeline = pipeline("sentiment-analysis", 
                                     model=model, 
                                     tokenizer=tokenizer,
                                     device=0 if torch.cuda.is_available() else -1)
        return sentiment_pipeline, "FinBERT (ê¸ˆìœµ ìµœì í™”)"
    except Exception as e:
        try:
            sentiment_pipeline = pipeline("sentiment-analysis",
                                         model="distilbert-base-uncased-finetuned-sst-2-english",
                                         device=0 if torch.cuda.is_available() else -1)
            return sentiment_pipeline, "DistilBERT (ì¼ë°˜ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„)"
        except:
            sentiment_pipeline = pipeline("sentiment-analysis",
                                         device=0 if torch.cuda.is_available() else -1)
            return sentiment_pipeline, "ê¸°ë³¸ Transformer ëª¨ë¸"

# ======================== ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ ========================

def preprocess_text(text):
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def chunk_text(text, max_length=512):
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
    sentences = re.split(r'[.!?]+', text)
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
        
        if len(current_chunk) + len(sentence) < max_length:
            current_chunk += sentence + ". "
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = sentence + ". "
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks if chunks else [text[:max_length]]

def analyze_sentiment_for_equity(text, sentiment_pipeline):
    """
    ì¢…ëª©ë³„ ì „ì²´ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„
    
    ì ìˆ˜ ê³„ì‚° ë°©ì‹:
    1. í…ìŠ¤íŠ¸ë¥¼ 512í† í° ë‹¨ìœ„ë¡œ ì²­í‚¹
    2. ê° ì²­í¬ë³„ë¡œ FinBERT ëª¨ë¸ì´ POSITIVE/NEGATIVE/NEUTRAL ë¶„ë¥˜ + ì‹ ë¢°ë„ ì ìˆ˜(0~1) ë°˜í™˜
    3. ìµœì¢… ì ìˆ˜ = (ê¸ì • ì²­í¬ ë¹„ìœ¨ Ã— í‰ê·  ê¸ì • ì‹ ë¢°ë„) - (ë¶€ì • ì²­í¬ ë¹„ìœ¨ Ã— í‰ê·  ë¶€ì • ì‹ ë¢°ë„)
    4. ë²”ìœ„: -1(ì™„ì „ ë¶€ì •) ~ +1(ì™„ì „ ê¸ì •)
    
    ë¶„ë¥˜ ê¸°ì¤€:
    - POSITIVE: ì ìˆ˜ > 0.2 (ê¸ì • ê¸°ì¤€ì„ )
    - NEGATIVE: ì ìˆ˜ < -0.2 (ë¶€ì • ê¸°ì¤€ì„ )
    - NEUTRAL: -0.2 â‰¤ ì ìˆ˜ â‰¤ 0.2
    
    ì°¸ê³ : ì‹¤ì œ earnings call í…ìŠ¤íŠ¸ëŠ” ëŒ€ë¶€ë¶„ ì¤‘ë¦½ì ì´ê±°ë‚˜ ì•½ê°„ ê¸ì •ì ì¸ ê²½í–¥ì´ ìˆì–´
          ë¶€ì •ì  ì ìˆ˜ê°€ ë“œë¬¼ê²Œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    if not text or len(text.strip()) == 0:
        return "NEUTRAL", 0.0
    
    text = preprocess_text(text)
    chunks = chunk_text(text, max_length=512)
    
    chunk_results = []
    for chunk in chunks:
        try:
            result = sentiment_pipeline(chunk, truncation=True, max_length=512)
            chunk_results.append(result[0])
        except Exception as e:
            continue
    
    if not chunk_results:
        return "NEUTRAL", 0.0
    
    # ê°ì • ì ìˆ˜ ì§‘ê³„
    positive_scores = [r['score'] for r in chunk_results if r['label'] in ['POSITIVE', 'positive']]
    negative_scores = [r['score'] for r in chunk_results if r['label'] in ['NEGATIVE', 'negative']]
    neutral_scores = [r['score'] for r in chunk_results if r['label'] in ['NEUTRAL', 'neutral']]
    
    # ìµœì¢… ì ìˆ˜ ê³„ì‚° (-1 ~ 1 ë²”ìœ„)
    # ê¸ì •/ë¶€ì • ì²­í¬ì˜ í‰ê·  ì‹ ë¢°ë„ì™€ ë¹„ìœ¨ì„ ëª¨ë‘ ê³ ë ¤
    avg_positive = np.mean(positive_scores) if positive_scores else 0
    avg_negative = np.mean(negative_scores) if negative_scores else 0
    
    positive_weight = len(positive_scores) / len(chunk_results)
    negative_weight = len(negative_scores) / len(chunk_results)
    
    # ìµœì¢… ì ìˆ˜: ê¸ì • ê¸°ì—¬ë„ - ë¶€ì • ê¸°ì—¬ë„
    final_score = (avg_positive * positive_weight) - (avg_negative * negative_weight)
    
    # ê°ì • ë¶„ë¥˜ (ì—„ê²©í•œ ê¸°ì¤€)
    if final_score > 0.2:
        sentiment = "POSITIVE"
    elif final_score < -0.2:
        sentiment = "NEGATIVE"
    else:
        sentiment = "NEUTRAL"
    
    return sentiment, final_score

def extract_keywords(text, n_words=15):
    """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ"""
    text = preprocess_text(text.lower())
    
    stop_words = {
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
        'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
        'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
        'should', 'may', 'might', 'must', 'can', 'that', 'this', 'as', 'if',
        'it', 'its', 'which', 'who', 'what', 'when', 'where', 'why', 'how',
        'all', 'each', 'every', 'both', 'either', 'neither', 'such', 'same',
        'so', 'than', 'then', 'they', 'them', 'their', 'we', 'us', 'our',
        'you', 'your', 'he', 'him', 'his', 'she', 'her', 'hers', 'i', 'me', 
        'my', 'mine', 'thank', 'thanks', 'good', 'day', 'now', 'bye', 'welcome',
        'hello', 'hi', 'ladies', 'gentlemen', 'everyone', 'conclude', 'concludes',
        'disconnect', 'today', 'call', 'conference', 'thank', 'think', 'year'
    }
    
    words = re.findall(r'\b[a-z]{3,}\b', text)
    filtered_words = [w for w in words if w not in stop_words and len(w) > 2]
    
    word_freq = Counter(filtered_words)
    return word_freq.most_common(n_words)

def calculate_equity_ranking(equity_df):
    """ì¢…ëª©ë³„ ìˆœìœ„ ê³„ì‚°"""
    equity_df = equity_df.copy()
    equity_df['Portfolio_Score'] = equity_df['Sentiment_Score']
    
    equity_df['Sentiment_Grade'] = equity_df['Sentiment_Score'].apply(
        lambda x: 'A+' if x > 0.6 else ('A' if x > 0.4 else ('B+' if x > 0.2 else 
                  ('B' if x > 0 else ('C' if x > -0.2 else ('D' if x > -0.4 else 'F')))))
    )
    
    equity_df['Investment_Preference'] = equity_df['Sentiment_Score'].apply(
        lambda x: 'ê°•ë ¥ ì¶”ì²œ' if x > 0.4 else ('ì¶”ì²œ' if x > 0.2 else ('ì¤‘ë¦½' if x > -0.2 else 'íšŒí”¼')))
    
    return equity_df.sort_values('Portfolio_Score', ascending=False)

# ======================== ì‹œê°í™” í•¨ìˆ˜ ========================

def plot_sentiment_distribution(df):
    """ì„¼í‹°ë¨¼íŠ¸ ë¶„í¬ ì‹œê°í™”"""
    sentiment_counts = df['Sentiment'].value_counts()
    
    colors = {
        'POSITIVE': '#28a745',
        'NEGATIVE': '#dc3545',
        'NEUTRAL': '#6c757d'
    }
    
    fig = go.Figure(data=[
        go.Bar(
            x=sentiment_counts.index,
            y=sentiment_counts.values,
            marker=dict(color=[colors.get(x, '#6c757d') for x in sentiment_counts.index]),
            text=sentiment_counts.values,
            textposition='auto',
        )
    ])
    
    fig.update_layout(
        title="ì „ì²´ ì„¼í‹°ë¨¼íŠ¸ ë¶„í¬",
        xaxis_title="ì„¼í‹°ë¨¼íŠ¸ ë¶„ë¥˜",
        yaxis_title="ì¢…ëª©ìˆ˜",
        template="plotly_white",
        height=400
    )
    
    return fig

def plot_equity_sentiment_scores(df):
    """ì¢…ëª©ë³„ ì„¼í‹°ë¨¼íŠ¸ ì ìˆ˜ ì‹œê°í™”"""
    df_sorted = df.sort_values('Sentiment_Score', ascending=False)
    
    colors = df_sorted['Sentiment_Score'].apply(
        lambda x: '#28a745' if x > 0.2 else ('#dc3545' if x < -0.2 else '#6c757d')
    )
    
    fig = go.Figure(data=[
        go.Bar(
            x=df_sorted['Equity'],
            y=df_sorted['Sentiment_Score'],
            marker=dict(color=colors),
            text=df_sorted['Sentiment_Score'].round(3),
            textposition='auto',
        )
    ])
    
    fig.add_hline(y=0, line_dash="dash", line_color="gray", opacity=0.5)
    fig.add_hline(y=0.2, line_dash="dot", line_color="green", opacity=0.3, 
                  annotation_text="ê¸ì • ê¸°ì¤€ì„  (0.2)")
    fig.add_hline(y=-0.2, line_dash="dot", line_color="red", opacity=0.3,
                  annotation_text="ë¶€ì • ê¸°ì¤€ì„  (-0.2)")
    
    fig.update_layout(
        title="ì¢…ëª©ë³„ ì„¼í‹°ë¨¼íŠ¸ (ë†’ì„ìˆ˜ë¡ ê¸ì •ì )<br><sub>ê¸ì • ê¸°ì¤€: >0.2 | ë¶€ì • ê¸°ì¤€: <-0.2 | ì¤‘ë¦½: -0.2~0.2</sub>",
        xaxis_title="ì¢…ëª©",
        yaxis_title="ì„¼í‹°ë¨¼íŠ¸",
        template="plotly_white",
        height=500,
        showlegend=False
    )
    
    return fig


def extract_sentiment_contributing_words(text, sentiment_pipeline, target_sentiment, top_n=100):
    """
    SHAPì„ ì‚¬ìš©í•˜ì—¬ ì„¼í‹°ë¨¼íŠ¸ì— ì‹¤ì œë¡œ ê¸°ì—¬í•œ ë‹¨ì–´ ì¶”ì¶œ
    
    Args:
        text: ë¶„ì„í•  í…ìŠ¤íŠ¸
        sentiment_pipeline: ì„¼í‹°ë¨¼íŠ¸ íŒŒì´í”„ë¼ì¸
        target_sentiment: 'POSITIVE', 'NEGATIVE', 'NEUTRAL'
        top_n: ì¶”ì¶œí•  ìƒìœ„ ë‹¨ì–´ ìˆ˜
    
    Returns:
        dict: {ë‹¨ì–´: ê¸°ì—¬ë„ ì ìˆ˜}
    """
    if not text or len(text.strip()) < 10:
        return {}
    
    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ì²­í‚¹
    text = preprocess_text(text)
    chunks = chunk_text(text, max_length=512)
    
    # ê° ì²­í¬ì—ì„œ ê¸°ì—¬ë„ ë†’ì€ ë‹¨ì–´ ì¶”ì¶œ
    word_contributions = {}
    
    model = sentiment_pipeline.model
    tokenizer = sentiment_pipeline.tokenizer
    
    # ì„¼í‹°ë¨¼íŠ¸ ë ˆì´ë¸” ë§¤í•‘
    sentiment_map = {
        'POSITIVE': ['positive', 'POSITIVE'],
        'NEGATIVE': ['negative', 'NEGATIVE'],
        'NEUTRAL': ['neutral', 'NEUTRAL']
    }
    
    for chunk in chunks[:5]:  # ì²˜ë¦¬ ì‹œê°„ì„ ìœ„í•´ ìµœëŒ€ 5ê°œ ì²­í¬ë§Œ
        try:
            # í† í°í™”
            inputs = tokenizer(chunk, return_tensors="pt", truncation=True, max_length=512)
            
            # ëª¨ë¸ ì˜ˆì¸¡
            outputs = model(**inputs)
            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
            
            # í•´ë‹¹ ì„¼í‹°ë¨¼íŠ¸ì˜ í™•ë¥ 
            predicted_label = sentiment_pipeline(chunk, truncation=True, max_length=512)[0]['label']
            
            # íƒ€ê²Ÿ ì„¼í‹°ë¨¼íŠ¸ê°€ ì•„ë‹ˆë©´ ìŠ¤í‚µ
            if predicted_label not in sentiment_map[target_sentiment]:
                continue
            
            # SHAP ê°’ ê³„ì‚° (ê°„ì†Œí™” ë²„ì „: attention weights ì‚¬ìš©)
            tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])
            
            # Attention weightsë¥¼ ê¸°ì—¬ë„ ê·¼ì‚¬ì¹˜ë¡œ ì‚¬ìš©
            with torch.no_grad():
                attention = model(**inputs, output_attentions=True).attentions
                # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ attention í‰ê· 
                avg_attention = attention[-1].mean(dim=1).squeeze().mean(dim=0)
            
            # í† í°ë³„ ê¸°ì—¬ë„ ì§‘ê³„
            for token, weight in zip(tokens, avg_attention):
                # íŠ¹ìˆ˜ í† í° ë° ì„œë¸Œì›Œë“œ ì²˜ë¦¬
                if token.startswith('##'):
                    token = token[2:]
                elif token in ['[CLS]', '[SEP]', '[PAD]']:
                    continue
                
                token = token.lower().strip()
                
                # stop words í•„í„°ë§
                stop_words = {
                    'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
                    'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
                    'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
                    'should', 'may', 'might', 'must', 'can', 'that', 'this', 'as', 'if',
                    'it', 'its', 'which', 'who', 'what', 'when', 'where', 'why', 'how',
                    'thank', 'thanks', 'think', 'year'
                }
                
                if token in stop_words or len(token) < 3:
                    continue
                
                # ê¸°ì—¬ë„ ëˆ„ì 
                if token in word_contributions:
                    word_contributions[token] += float(weight)
                else:
                    word_contributions[token] = float(weight)
        
        except Exception as e:
            continue
    
    # ìƒìœ„ Nê°œ ë‹¨ì–´ ë°˜í™˜
    sorted_words = sorted(word_contributions.items(), key=lambda x: x[1], reverse=True)
    return dict(sorted_words[:top_n])

def plot_sentiment_wordcloud(text, sentiment, sentiment_pipeline, title="ì„¼í‹°ë¨¼íŠ¸ ê¸°ì—¬ ì›Œë“œí´ë¼ìš°ë“œ"):
    """ì„¼í‹°ë¨¼íŠ¸ ê¸°ì—¬ë„ ê¸°ë°˜ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±"""
    if not text or len(text.strip()) < 10:
        return None
    
    # ì„¼í‹°ë¨¼íŠ¸ì— ê¸°ì—¬í•œ ë‹¨ì–´ ì¶”ì¶œ
    word_scores = extract_sentiment_contributing_words(text, sentiment_pipeline, sentiment, top_n=100)
    
    if not word_scores:
        return None
    
    # WordCloud ìƒì„± (ë¹ˆë„ìˆ˜ ëŒ€ì‹  ê¸°ì—¬ë„ ì‚¬ìš©)
    wordcloud = WordCloud(
        width=800,
        height=400,
        background_color='white',
        colormap='RdYlGn' if sentiment == 'POSITIVE' else ('Reds_r' if sentiment == 'NEGATIVE' else 'Blues'),
        max_words=80,
        relative_scaling=0.5,
        min_font_size=10
    ).generate_from_frequencies(word_scores)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    ax.set_title(title, fontsize=16, fontweight='bold')
    
    return fig






def plot_wordcloud(text, title="ì›Œë“œí´ë¼ìš°ë“œ"):
    """ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±"""
    if not text or len(text.strip()) < 10:
        return None
    
    wordcloud = WordCloud(
        width=800,
        height=400,
        background_color='white',
        colormap='viridis',
        max_words=100,
        relative_scaling=0.5,
        min_font_size=10
    ).generate(text)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    ax.set_title(title, fontsize=16, fontweight='bold')
    
    return fig

def plot_top_equities_comparison(df, top_n=10):
    """ìƒìœ„ ì¢…ëª© ë¹„êµ ì°¨íŠ¸"""
    # Investment_Preference ì»¬ëŸ¼ ì¶”ê°€
    df_with_pref = df.copy()
    df_with_pref['Investment_Preference'] = df_with_pref['Sentiment_Score'].apply(
        lambda x: 'ê°•ë ¥ ì¶”ì²œ' if x > 0.4 else ('ì¶”ì²œ' if x > 0.2 else ('ì¤‘ë¦½' if x > -0.2 else 'íšŒí”¼'))
    )
    
    df_top = df_with_pref.nlargest(top_n, 'Sentiment_Score')
    
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=("ì„¼í‹°ë¨¼íŠ¸ Top 10", "íˆ¬ì ì„ í˜¸ë„ ë¶„í¬"),
        specs=[[{"type": "bar"}, {"type": "pie"}]]
    )
    
    # ë§‰ëŒ€ ì°¨íŠ¸
    fig.add_trace(
        go.Bar(
            x=df_top['Equity'],
            y=df_top['Sentiment_Score'],
            marker_color='lightblue',
            text=df_top['Sentiment_Score'].round(3),
            textposition='auto',
            showlegend=False
        ),
        row=1, col=1
    )
    
    # íŒŒì´ ì°¨íŠ¸
    preference_counts = df_with_pref['Investment_Preference'].value_counts()
    fig.add_trace(
        go.Pie(
            labels=preference_counts.index,
            values=preference_counts.values,
            marker_colors=['#28a745', '#17a2b8', '#ffc107', '#dc3545'],
        ),
        row=1, col=2
    )
    
    fig.update_layout(height=400, template="plotly_white")
    return fig

def plot_document_length_analysis(df):
    """ë¬¸ì„œ ê¸¸ì´ ë¶„ì„"""
    df['Text_Length'] = df['Combined_Text'].str.len()
    
    fig = px.scatter(
        df,
        x='Text_Length',
        y='Sentiment_Score',
        color='Sentiment',
        size='Text_Length',
        hover_data=['Equity'],
        title="ë¬¸ì„œ ê¸¸ì´ vs ì„¼í‹°ë¨¼íŠ¸",
        labels={'Text_Length': 'ë¬¸ì„œ ê¸¸ì´ (ë¬¸ì ìˆ˜)', 'Sentiment_Score': 'ì„¼í‹°ë¨¼íŠ¸'},
        color_discrete_map={'POSITIVE': '#28a745', 'NEGATIVE': '#dc3545', 'NEUTRAL': '#6c757d'}
    )
    
    fig.update_layout(height=400, template="plotly_white")
    return fig

def plot_sentiment_score_distribution(df):
    """ì„¼í‹°ë¨¼íŠ¸ ë¶„í¬"""
    fig = go.Figure()
    
    fig.add_trace(go.Histogram(
        x=df['Sentiment_Score'],
        nbinsx=30,
        marker_color='lightblue',
        opacity=0.7,
    ))
    
    fig.add_vline(x=0, line_dash="dash", line_color="gray", opacity=0.5)
    fig.add_vline(x=df['Sentiment_Score'].mean(), line_dash="dot", line_color="red", 
                  annotation_text=f"í‰ê· : {df['Sentiment_Score'].mean():.3f}")
    
    fig.update_layout(
        title="ì„¼í‹°ë¨¼íŠ¸ ë¶„í¬",
        xaxis_title="ì„¼í‹°ë¨¼íŠ¸",
        yaxis_title="ì¢…ëª©ìˆ˜",
        template="plotly_white",
        height=400
    )
    
    return fig

def plot_sentiment_comparison_radar(df):
    """ì„¼í‹°ë¨¼íŠ¸ ìƒì„¸ ë¶„ì„ ì°¨íŠ¸"""
    top10 = df.nlargest(10, 'Sentiment_Score')
    
    fig = go.Figure(data=[
        go.Bar(
            x=top10['Equity'],
            y=top10['Sentiment_Score'],
            marker=dict(
                color=top10['Sentiment_Score'],
                colorscale='RdYlGn',
                showscale=True,
                colorbar=dict(title="ì„¼í‹°ë¨¼íŠ¸")
            ),
            text=top10['Sentiment_Score'].round(3),
            textposition='auto',
        )
    ])
    
    fig.update_layout(
        title="ìƒìœ„ 10ê°œ ì¢…ëª© ì„¼í‹°ë¨¼íŠ¸ ìƒì„¸",
        xaxis_title="ì¢…ëª©",
        yaxis_title="ì„¼í‹°ë¨¼íŠ¸",
        template="plotly_white",
        height=500
    )
    
    return fig

# ======================== Streamlit ë©”ì¸ ì•± ========================

def main():
    st.title("ğŸ“Š Portfolio Sentiment Analysis")
    st.markdown("Transformer ê¸°ë°˜ í…ìŠ¤íŠ¸ ì„¼í‹°ë¨¼íŠ¸")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.markdown("## âš™ï¸ ì„¤ì •")
    
    uploaded_file = st.sidebar.file_uploader(
        "CSV íŒŒì¼ ì—…ë¡œë“œ",
        type=['csv'],
        help="Document Title, Date, Equity, 0-6 ì—´ì„ í¬í•¨í•œ CSV íŒŒì¼"
    )
    
    analyze_button = st.sidebar.button("ğŸ“ˆ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ì‹¤í–‰", key="analyze_main")
    
    if uploaded_file is not None:
        # íŒŒì¼ ë¡œë“œ
        df = pd.read_csv(uploaded_file)
        
        st.sidebar.success("âœ… íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
        st.sidebar.markdown("---")
        
        # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
        with st.sidebar.expander("ğŸ“‹ ë°ì´í„° ì •ë³´"):
            st.write(f"ì´ í–‰ ìˆ˜: {len(df)}")
            st.write(f"ì´ ì¢…ëª© ìˆ˜: {df['Equity'].nunique()}")
            st.write(f"ì»¬ëŸ¼: {', '.join(df.columns.tolist())}")
        
        if analyze_button or 'analysis_complete' not in st.session_state:
            st.session_state.analysis_complete = False
            
            with st.spinner("ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘..."):
                sentiment_pipeline, model_name = load_sentiment_model()
                st.session_state.sentiment_pipeline = sentiment_pipeline
            
            st.info(f"âœ… ëª¨ë¸: {model_name}")
            
            with st.spinner("â³ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ì§„í–‰ ì¤‘..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # ì¢…ëª©ë³„ë¡œ í…ìŠ¤íŠ¸ í†µí•© ë° ë¶„ì„
                text_columns = [str(i) for i in range(7) if str(i) in df.columns]
                
                # ì¢…ëª©ë³„ë¡œ ê·¸ë£¹í™”
                equity_groups = df.groupby('Equity')
                
                results = []
                total_equities = len(equity_groups)
                
                for idx, (equity, group) in enumerate(equity_groups):
                    # ë™ì¼ Document Titleì´ ìˆëŠ” ê²½ìš° í‰ê·  ê³„ì‚°
                    doc_results = []
                    
                    for doc_title in group['Document Title'].unique():
                        doc_rows = group[group['Document Title'] == doc_title]
                        
                        # ëª¨ë“  í…ìŠ¤íŠ¸ ì—´ í†µí•©
                        combined_text = ' '.join(
                            doc_rows[text_columns].fillna('').astype(str).values.flatten()
                        )
                        
                        sentiment, score = analyze_sentiment_for_equity(combined_text, sentiment_pipeline)
                        doc_results.append({
                            'sentiment': sentiment,
                            'score': score,
                            'text': combined_text
                        })
                    
                    # ë™ì¼ ì¢…ëª©ì˜ ì—¬ëŸ¬ Document í‰ê· 
                    avg_score = np.mean([r['score'] for r in doc_results])
                    
                    # ìµœì¢… ê°ì • ì¬ë¶„ë¥˜
                    if avg_score > 0.2:
                        final_sentiment = "POSITIVE"
                    elif avg_score < -0.2:
                        final_sentiment = "NEGATIVE"
                    else:
                        final_sentiment = "NEUTRAL"
                    
                    # ëª¨ë“  í…ìŠ¤íŠ¸ í†µí•© (ì›Œë“œí´ë¼ìš°ë“œìš©)
                    all_text = ' '.join([r['text'] for r in doc_results])
                    
                    results.append({
                        'Equity': equity,
                        'Sentiment': final_sentiment,
                        'Sentiment_Score': avg_score,
                        'Document_Count': len(doc_results),
                        'Combined_Text': all_text
                    })
                    
                    progress_bar.progress((idx + 1) / total_equities)
                    status_text.text(f"ë¶„ì„ ì¤‘: {equity} ({idx + 1}/{total_equities})")
                
                result_df = pd.DataFrame(results)
                
                progress_bar.progress(100)
                status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
            
            st.session_state.analysis_complete = True
            st.session_state.analysis_df = result_df
        
        if st.session_state.analysis_complete:
            df = st.session_state.analysis_df
            
            st.success("âœ… ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ì™„ë£Œ!")
            
            # ==================== ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ ====================
            st.markdown("---")
            st.subheader("ğŸ“Š ì£¼ìš” ë©”íŠ¸ë¦­")
            
            sentiment_counts = df['Sentiment'].value_counts()
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "ê¸ì •ì  ì¢…ëª©",
                    f"{sentiment_counts.get('POSITIVE', 0)}ê°œ",
                    f"{sentiment_counts.get('POSITIVE', 0) / len(df) * 100:.1f}%"
                )
            
            with col2:
                st.metric(
                    "ë¶€ì •ì  ì¢…ëª©",
                    f"{sentiment_counts.get('NEGATIVE', 0)}ê°œ",
                    f"{sentiment_counts.get('NEGATIVE', 0) / len(df) * 100:.1f}%"
                )
            
            with col3:
                st.metric(
                    "ì¤‘ë¦½ì  ì¢…ëª©",
                    f"{sentiment_counts.get('NEUTRAL', 0)}ê°œ",
                    f"{sentiment_counts.get('NEUTRAL', 0) / len(df) * 100:.1f}%"
                )
            
            with col4:
                top_equity = df.nlargest(1, 'Sentiment_Score').iloc[0]
                st.metric(
                    "ìµœê³  ì„ í˜¸ ì¢…ëª©",
                    top_equity['Equity'],
                    f"{top_equity['Sentiment_Score']:.3f}"
                )
            
            # Top 5 ì¢…ëª© í‘œì‹œ
            st.markdown("### ğŸ† ì„¼í‹°ë¨¼íŠ¸ Top 5")
            top5 = df.nlargest(5, 'Sentiment_Score')[['Equity', 'Sentiment_Score', 'Sentiment']]
            
            cols = st.columns(5)
            for idx, (_, row) in enumerate(top5.iterrows()):
                with cols[idx]:
                    st.markdown(f"**#{idx+1} {row['Equity']}**")
                    st.markdown(f"<p class='{row['Sentiment'].lower()}'>{row['Sentiment_Score']:.3f}</p>", 
                               unsafe_allow_html=True)
            
            # ==================== ì‹œê°í™” ====================
            st.markdown("---")
            st.subheader("ğŸ“ˆ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ìƒì„¸")
            
            tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
                "ì„¼í‹°ë¨¼íŠ¸ ë¶„í¬", "ì¢…ëª© ì ìˆ˜", "ìƒìœ„ ì¢…ëª© ë¹„êµ", "ì›Œë“œí´ë¼ìš°ë“œ", "ë¬¸ì„œ ë¶„ì„", "ìƒì„¸ ë¶„ì„"
            ])
            
            with tab1:
                st.plotly_chart(plot_sentiment_distribution(df), width="stretch")
                st.plotly_chart(plot_sentiment_score_distribution(df), width="stretch")
            
            with tab2:
                st.plotly_chart(plot_equity_sentiment_scores(df), width="stretch")
                st.plotly_chart(plot_sentiment_comparison_radar(df), width="stretch")
                
                # ê°ì • ë¶„ë¥˜ ê¸°ì¤€ ì„¤ëª… ì¶”ê°€
                st.info("""
                **ğŸ“Œ ì„¼í‹°ë¨¼íŠ¸ ë¶„ë¥˜ ê¸°ì¤€ **
                
                - **ê¸ì • (POSITIVE)**: ì„¼í‹°ë¨¼íŠ¸ > 0.2
                - **ì¤‘ë¦½ (NEUTRAL)**: -0.2 â‰¤ ì„¼í‹°ë¨¼íŠ¸ â‰¤ 0.2  
                - **ë¶€ì • (NEGATIVE)**: ì„¼í‹°ë¨¼íŠ¸ < -0.2
                
                **ğŸ’¡ ë¶€ì •ì  ì¢…ëª©ì´ ì ì€ ì´ìœ :**
                Earnings call ë° ì¬ë¬´ ë³´ê³ ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì¤‘ë¦½ì ì´ê±°ë‚˜ ê¸ì •ì ì¸ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. 
                ì‹¤ì œë¡œ ë¶€ì •ì ì¸ ë‚´ìš©ë„ ì™„ê³¡í•˜ê²Œ í‘œí˜„ë˜ëŠ” ê²½ìš°ê°€ ë§ì•„, ëª…í™•íˆ ë¶€ì •ì ì¸ ì ìˆ˜(-0.2 ì´í•˜)ë¥¼ ë°›ëŠ” ê²½ìš°ëŠ” ë“œë­…ë‹ˆë‹¤.
                """)
            
            with tab3:
                st.plotly_chart(plot_top_equities_comparison(df), width="stretch")

            with tab4:
                sentiment_pipeline = st.session_state.get('sentiment_pipeline')  # ì´ ì¤„ ì¶”ê°€
                st.markdown("### ì›Œë“œí´ë¼ìš°ë“œ ë¶„ì„")
    
                # ë¶„ì„ ëª¨ë“œ ì„ íƒ
                analysis_mode = st.radio(
                    "ë¶„ì„ ëª¨ë“œ ì„ íƒ",
                    options=["ë¹ˆë„ ê¸°ë°˜ (ê¸°ë³¸)", "ì„¼í‹°ë¨¼íŠ¸ ê¸°ì—¬ë„ ê¸°ë°˜ (AI)"],
                    horizontal=True,
                    help="ê¸°ì—¬ë„ ê¸°ë°˜: ì‹¤ì œë¡œ ì„¼í‹°ë¨¼íŠ¸ ë¶„ë¥˜ì— ì˜í–¥ì„ ì¤€ ë‹¨ì–´ë§Œ í‘œì‹œ (ì²˜ë¦¬ ì‹œê°„ ë” ì†Œìš”)"
                )
    
                wc_option = st.radio(
                    "ì›Œë“œí´ë¼ìš°ë“œ ìœ í˜• ì„ íƒ",
                    options=["ì„¼í‹°ë¨¼íŠ¸ë³„", "ì¢…ëª©ë³„"],
                    horizontal=True
                )
    
                if analysis_mode == "ë¹ˆë„ ê¸°ë°˜ (ê¸°ë³¸)":
                    # ê¸°ì¡´ ì½”ë“œ ìœ ì§€
                    if wc_option == "ì„¼í‹°ë¨¼íŠ¸ë³„":
                        sentiment_filter = st.selectbox(
                            "ì„¼í‹°ë¨¼íŠ¸ ì„ íƒ",
                            options=["ì „ì²´"] + df['Sentiment'].unique().tolist()
                        )
            
                        if sentiment_filter == "ì „ì²´":
                            text_data = ' '.join(df['Combined_Text'].tolist())
                            title = "All Word Cloud"
                        else:
                            text_data = ' '.join(df[df['Sentiment'] == sentiment_filter]['Combined_Text'].tolist())
                            title = f"{sentiment_filter} Word Cloud"
            
                        wordcloud_fig = plot_wordcloud(text_data, title)
                        if wordcloud_fig:
                            st.pyplot(wordcloud_fig, use_container_width=True)
                        else:
                            st.warning("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
                    else:  # ì¢…ëª©ë³„
                        equity_filter = st.selectbox(
                            "ì¢…ëª© ì„ íƒ",
                            options=df['Equity'].tolist()
                        )
            
                        text_data = df[df['Equity'] == equity_filter]['Combined_Text'].iloc[0]
                        title = f"{equity_filter} Word Cloud"
            
                        wordcloud_fig = plot_wordcloud(text_data, title)
                        if wordcloud_fig:
                            st.pyplot(wordcloud_fig, use_container_width=True)
                        else:
                            st.warning("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
                else:  # ì„¼í‹°ë¨¼íŠ¸ ê¸°ì—¬ë„ ê¸°ë°˜
                    st.info("â³ AI ëª¨ë¸ì´ ì„¼í‹°ë¨¼íŠ¸ì— ì‹¤ì œë¡œ ê¸°ì—¬í•œ ë‹¨ì–´ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")
        
                    if wc_option == "ì„¼í‹°ë¨¼íŠ¸ë³„":
                        sentiment_filter = st.selectbox(
                            "ì„¼í‹°ë¨¼íŠ¸ ì„ íƒ",
                            options=df['Sentiment'].unique().tolist(),
                            key="sentiment_contrib"
                        )
            
                        text_data = ' '.join(df[df['Sentiment'] == sentiment_filter]['Combined_Text'].tolist())
                        title = f"{sentiment_filter} - ì„¼í‹°ë¨¼íŠ¸ ê¸°ì—¬ ë‹¨ì–´"
            
                        with st.spinner("ë¶„ì„ ì¤‘..."):
                            wordcloud_fig = plot_sentiment_wordcloud(
                                text_data, 
                                sentiment_filter, 
                                sentiment_pipeline,
                                title
                            )
            
                        if wordcloud_fig:
                            st.pyplot(wordcloud_fig, use_container_width=True)
                            st.caption("ğŸ’¡ ë‹¨ì–´ í¬ê¸° = í•´ë‹¹ ì„¼í‹°ë¨¼íŠ¸ ë¶„ë¥˜ì— ëŒ€í•œ AI ëª¨ë¸ì˜ ê¸°ì—¬ë„")
                        else:
                            st.warning("ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
                    else:  # ì¢…ëª©ë³„
                        equity_filter = st.selectbox(
                            "ì¢…ëª© ì„ íƒ",
                            options=df['Equity'].tolist(),
                            key="equity_contrib"
                        )
            
                        equity_data = df[df['Equity'] == equity_filter].iloc[0]
                        text_data = equity_data['Combined_Text']
                        sentiment = equity_data['Sentiment']
                        title = f"{equity_filter} - {sentiment} ê¸°ì—¬ ë‹¨ì–´"
            
                        with st.spinner("ë¶„ì„ ì¤‘..."):
                            wordcloud_fig = plot_sentiment_wordcloud(
                                text_data,
                                sentiment,
                                sentiment_pipeline,
                                title
                            )
            
                        if wordcloud_fig:
                            st.pyplot(wordcloud_fig, use_container_width=True)
                            st.caption("ğŸ’¡ ì´ ì¢…ëª©ì´ í•´ë‹¹ ì„¼í‹°ë¨¼íŠ¸ë¡œ ë¶„ë¥˜ëœ ì´ìœ ê°€ ë˜ëŠ” í•µì‹¬ ë‹¨ì–´ë“¤ì…ë‹ˆë‹¤.")
                        else:
                            st.warning("ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            with tab5:
                st.plotly_chart(plot_document_length_analysis(df), width="stretch")
                
                # í†µê³„ ìš”ì•½
                st.markdown("### ğŸ“Š ë¬¸ì„œ í†µê³„")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("í‰ê·  ë¬¸ì„œ ê¸¸ì´", f"{df['Combined_Text'].str.len().mean():.0f} ì")
                with col2:
                    st.metric("ìµœëŒ€ ë¬¸ì„œ ê¸¸ì´", f"{df['Combined_Text'].str.len().max():.0f} ì")
                with col3:
                    st.metric("ìµœì†Œ ë¬¸ì„œ ê¸¸ì´", f"{df['Combined_Text'].str.len().min():.0f} ì")
            
            with tab6:
                st.markdown("### ğŸ“‹ ìƒì„¸ ë¶„ì„")
                
                # ì¢…ëª©ë³„ ìˆœìœ„
                equity_ranking = calculate_equity_ranking(df)
                
                st.markdown("#### ğŸ† ì¢…ëª© ìˆœìœ„ ë° í¬íŠ¸í´ë¦¬ì˜¤ í‰ê°€")
                
                display_ranking = equity_ranking[['Sentiment_Score', 'Sentiment', 
                                                  'Document_Count', 'Sentiment_Grade', 
                                                  'Investment_Preference']].copy()
                display_ranking.columns = ['ì„¼í‹°ë¨¼íŠ¸', 'ì„¼í‹°ë¨¼íŠ¸ ë¶„ë¥˜', 'ë¬¸ì„œìˆ˜', 'ë“±ê¸‰', 'íˆ¬ìì„ í˜¸ë„']
                display_ranking = display_ranking.round(4)
                
                st.dataframe(
                    display_ranking,
                    use_container_width=True,
                    height=400
                )
                
                # ì¢…ëª©ë³„ í‚¤ì›Œë“œ
                st.markdown("#### ğŸ” ì¢…ëª©ë³„ ì£¼ìš” í‚¤ì›Œë“œ")
                
                selected_equity = st.selectbox("ì¢…ëª© ì„ íƒ", df['Equity'].tolist(), key="keyword_equity")
                
                equity_text = df[df['Equity'] == selected_equity]['Combined_Text'].iloc[0]
                keywords = extract_keywords(equity_text, n_words=20)
                
                if keywords:
                    keyword_df = pd.DataFrame(keywords, columns=['í‚¤ì›Œë“œ', 'ë¹ˆë„'])
                    
                    fig = px.bar(
                        keyword_df.head(15),
                        x='ë¹ˆë„',
                        y='í‚¤ì›Œë“œ',
                        orientation='h',
                        title=f"{selected_equity} - ì£¼ìš” í‚¤ì›Œë“œ Top 15",
                        color='ë¹ˆë„',
                        color_continuous_scale='Viridis'
                    )
                    fig.update_layout(height=500)
                    st.plotly_chart(fig, width="stretch")
                else:
                    st.info("ì¶”ì¶œí•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # ê°ì •ë³„ í†µê³„
                st.markdown("#### ğŸ’­ ê°ì • ë¶„ë¥˜ë³„ í†µê³„")
                
                sentiment_stats = df.groupby('Sentiment').agg({
                    'Equity': 'count',
                    'Sentiment_Score': ['mean', 'std', 'min', 'max']
                }).round(4)
                
                sentiment_stats.columns = ['ì¢…ëª©ìˆ˜', 'í‰ê· ì ìˆ˜', 'í‘œì¤€í¸ì°¨', 'ìµœì†Œ', 'ìµœëŒ€']
                st.dataframe(sentiment_stats, use_container_width=True)


            # ==================== ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ ====================
            st.markdown("---")
            st.subheader("ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # ë¶„ì„ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ
                result_csv = df[['Equity', 'Sentiment', 'Sentiment_Score', 'Document_Count']].to_csv(index=False)
                st.download_button(
                    label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ (CSV)",
                    data=result_csv,
                    file_name=f"sentiment_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
            
            with col2:
                # ì¢…ëª© ìˆœìœ„ ë‹¤ìš´ë¡œë“œ
                equity_ranking = calculate_equity_ranking(df)
                ranking_csv = equity_ranking.to_csv()
                st.download_button(
                    label="ğŸ“Š ì¢…ëª© ìˆœìœ„ (CSV)",
                    data=ranking_csv,
                    file_name=f"equity_ranking_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
    
    else:
        st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        
        st.markdown("---")
        st.subheader("ğŸ“ ì‚¬ìš© ë°©ë²•")
        st.markdown("""
        1. **íŒŒì¼ ì—…ë¡œë“œ**: CSV íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤
           - í•„ìˆ˜ ì—´: Document Title, Date, Equity
           - í…ìŠ¤íŠ¸ ì—´: 0, 1, 2, 3, 4, 5, 6 (ìë™ìœ¼ë¡œ í†µí•©ë©ë‹ˆë‹¤)
        
        2. **ë¶„ì„ ì‹¤í–‰**: "ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ì‹¤í–‰" ë²„íŠ¼ì„ í´ë¦­í•©ë‹ˆë‹¤
           - ìµœì‹  Transformer ëª¨ë¸ (FinBERT) ì‚¬ìš©
           - ê¸ˆìœµ ë„ë©”ì¸ì— ìµœì í™”ëœ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„
        
        3. **ê²°ê³¼ í™•ì¸**: 
           - ğŸ“Š ì„¼í‹°ë¨¼íŠ¸ ë¶„í¬ ë° ì‹œê°í™”
           - ğŸ† ì¢…ëª©ë³„ ìˆœìœ„ ë° í¬íŠ¸í´ë¦¬ì˜¤ ì ìˆ˜
           - ğŸ” ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„
           - ğŸ’­ ì„¼í‹°ë¨¼íŠ¸ë³„ ìƒì„¸ í†µê³„
        
        4. **ê²°ê³¼ ë‹¤ìš´ë¡œë“œ**: ë¶„ì„ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤
        """)
        
        st.markdown("---")
        st.subheader("ğŸ¤– ì‚¬ìš© ëª¨ë¸")
        st.markdown("""
        - **FinBERT**: BERTë¥¼ ê¸ˆìœµ í…ìŠ¤íŠ¸ë¡œ íŒŒì¸íŠœë‹í•œ ìµœì‹  ëª¨ë¸
        - **Transformer Pipeline**: ê³ ì„±ëŠ¥ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„
        - **Word Cloud**: ì„¼í‹°ë¨¼íŠ¸ë³„/ì¢…ëª©ë³„ ì£¼ìš” ë‹¨ì–´ ì‹œê°í™”
        
        ì´ ëª¨ë¸ë“¤ì€ ì „í†µì  ë°©ì‹ë³´ë‹¤ í›¨ì”¬ ë†’ì€ ì •í™•ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
        """)

if __name__ == "__main__":
    main()
