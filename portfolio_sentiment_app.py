# Portfolio Sentiment Analysis with Transformer-based NLP
# Streamlit Application for Financial Sentiment Analysis

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import torch
import shap
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter
import re
from datetime import datetime
import warnings
import os

warnings.filterwarnings('ignore')

os.environ['CURL_CA_BUNDLE'] = ''
os.environ['REQUESTS_CA_BUNDLE'] = ''

# í˜ì´ì§€ êµ¬ì„± ì„¤ì •
st.set_page_config(
    page_title="Sentiment Analysis",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    .positive {
        color: #28a745;
        font-weight: bold;
    }
    .negative {
        color: #dc3545;
        font-weight: bold;
    }
    .neutral {
        color: #6c757d;
        font-weight: bold;
    }
    .top-equity {
        font-size: 24px;
        font-weight: bold;
        color: #0066cc;
    }
    </style>
    """, unsafe_allow_html=True)

# ======================== ëª¨ë¸ ìºì‹± ì„¤ì • ========================
@st.cache_resource
def load_sentiment_model():
    """FinBERT ëª¨ë¸ ë¡œë“œ"""
    try:
        model_name = "ProsusAI/finbert"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        sentiment_pipeline = pipeline("sentiment-analysis", 
                                     model=model, 
                                     tokenizer=tokenizer,
                                     device=0 if torch.cuda.is_available() else -1)
        return sentiment_pipeline, "FinBERT (ê¸ˆìœµ ìµœì í™”)"
    except Exception as e:
        try:
            sentiment_pipeline = pipeline("sentiment-analysis",
                                         model="distilbert-base-uncased-finetuned-sst-2-english",
                                         device=0 if torch.cuda.is_available() else -1)
            return sentiment_pipeline, "DistilBERT (ì¼ë°˜ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„)"
        except:
            sentiment_pipeline = pipeline("sentiment-analysis",
                                         device=0 if torch.cuda.is_available() else -1)
            return sentiment_pipeline, "ê¸°ë³¸ Transformer ëª¨ë¸"

# ======================== ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ ========================

def preprocess_text(text):
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

def chunk_text(text, max_length=512):
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
    sentences = re.split(r'[.!?]+', text)
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
        
        if len(current_chunk) + len(sentence) < max_length:
            current_chunk += sentence + ". "
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = sentence + ". "
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks if chunks else [text[:max_length]]

def analyze_sentiment_for_equity(text, sentiment_pipeline):
    """
    AI ê°€ì¤‘í‰ê·  ë°©ì‹ì˜ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„
    
    ì‘ë™ ë°©ì‹:
    1. í…ìŠ¤íŠ¸ë¥¼ 512í† í° ë‹¨ìœ„ë¡œ ì²­í‚¹
    2. ê° ì²­í¬ë³„ë¡œ FinBERTê°€ POSITIVE/NEGATIVE/NEUTRAL ë¶„ë¥˜ + ì‹ ë¢°ë„ ë°˜í™˜
    3. ê° ì„¼í‹°ë¨¼íŠ¸ì˜ ì‹ ë¢°ë„ë¥¼ ëˆ„ì  (AIì˜ í™•ì‹ ë„ë¥¼ ê·¸ëŒ€ë¡œ ë°˜ì˜)
    4. ê°€ì¥ ë†’ì€ ëˆ„ì  ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ì„¼í‹°ë¨¼íŠ¸ë¥¼ ìµœì¢… ì„ íƒ
    5. ìµœì¢… ì ìˆ˜ = í•´ë‹¹ ì„¼í‹°ë¨¼íŠ¸ì˜ ì‹ ë¢°ë„ ë¹„ìœ¨ (0~1 ë²”ìœ„)
    
    ì˜ˆì‹œ:
    - POSITIVE ì²­í¬ë“¤ì˜ ì‹ ë¢°ë„ í•©: 45.2
    - NEGATIVE ì²­í¬ë“¤ì˜ ì‹ ë¢°ë„ í•©: 8.3
    - NEUTRAL ì²­í¬ë“¤ì˜ ì‹ ë¢°ë„ í•©: 22.1
    - ì´í•©: 75.6
    - ìµœì¢…: POSITIVE, ì ìˆ˜ = 45.2/75.6 = 0.598
    
    ì¥ì :
    - ì‚¬ëŒì´ ì •í•œ ì„ê³„ê°’(Â±0.2) ì—†ìŒ
    - AI ëª¨ë¸ì˜ íŒë‹¨ì„ 100% ì‹ ë¢°
    - ì‹ ë¢°ë„ ê°•ë„ê¹Œì§€ ë°˜ì˜ (0.95 ê¸ì • > 0.55 ê¸ì •)
    """
    if not text or len(text.strip()) == 0:
        return "NEUTRAL", 0.0
    
    text = preprocess_text(text)
    chunks = chunk_text(text, max_length=512)
    
    # ì„¼í‹°ë¨¼íŠ¸ë³„ ì‹ ë¢°ë„ ëˆ„ì 
    sentiment_scores = {'POSITIVE': 0.0, 'NEGATIVE': 0.0, 'NEUTRAL': 0.0}
    
    for chunk in chunks:
        try:
            result = sentiment_pipeline(chunk, truncation=True, max_length=512)
            label = result[0]['label'].upper()  # ëŒ€ì†Œë¬¸ì í†µì¼
            score = result[0]['score']  # AIì˜ ì‹ ë¢°ë„ (0~1)
            
            # AIì˜ ì‹ ë¢°ë„ë¥¼ ê·¸ëŒ€ë¡œ ëˆ„ì 
            if label in sentiment_scores:
                sentiment_scores[label] += score
        except Exception as e:
            continue
    
    # ë¶„ì„ ì‹¤íŒ¨ ì‹œ ì¤‘ë¦½ ë°˜í™˜
    total_score = sum(sentiment_scores.values())
    if total_score == 0:
        return "NEUTRAL", 0.0
    
    # ê°€ì¥ ë†’ì€ ëˆ„ì  ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ì„¼í‹°ë¨¼íŠ¸ ì„ íƒ
    final_sentiment = max(sentiment_scores, key=sentiment_scores.get)
    
    # ìµœì¢… ì ìˆ˜: í•´ë‹¹ ì„¼í‹°ë¨¼íŠ¸ì˜ ë¹„ìœ¨ (0~1)
    final_score = sentiment_scores[final_sentiment] / total_score
    
    return final_sentiment, final_score

def extract_keywords(text, n_words=15):
    """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ"""
    text = preprocess_text(text.lower())
    
    stop_words = {
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
        'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
        'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
        'should', 'may', 'might', 'must', 'can', 'that', 'this', 'as', 'if',
        'it', 'its', 'which', 'who', 'what', 'when', 'where', 'why', 'how',
        'all', 'each', 'every', 'both', 'either', 'neither', 'such', 'same',
        'so', 'than', 'then', 'they', 'them', 'their', 'we', 'us', 'our',
        'you', 'your', 'he', 'him', 'his', 'she', 'her', 'hers', 'i', 'me', 
        'my', 'mine', 'thank', 'thanks', 'good', 'day', 'now', 'bye', 'welcome',
        'hello', 'hi', 'ladies', 'gentlemen', 'everyone', 'conclude', 'concludes',
        'disconnect', 'today', 'call', 'conference', 'thank', 'think', 'year'
    }
    
    words = re.findall(r'\b[a-z]{3,}\b', text)
    filtered_words = [w for w in words if w not in stop_words and len(w) > 2]
    
    word_freq = Counter(filtered_words)
    return word_freq.most_common(n_words)

def calculate_equity_ranking(equity_df):
    """ì¢…ëª©ë³„ ìˆœìœ„ ê³„ì‚° (AI ê¸°ë°˜ ì ìˆ˜ ì‚¬ìš©)"""
    equity_df = equity_df.copy()
    equity_df['Portfolio_Score'] = equity_df['Sentiment_Score']
    
    # ì ìˆ˜ ë²”ìœ„ê°€ 0~1ì´ë¯€ë¡œ ë“±ê¸‰ ê¸°ì¤€ ë³€ê²½
    equity_df['Sentiment_Grade'] = equity_df['Sentiment_Score'].apply(
        lambda x: 'S' if x > 0.8 else (
                  'A+' if x > 0.7 else (
                  'A' if x > 0.6 else (
                  'B' if x > 0.5 else (
                  'C' if x > 0.4 else (
                  'D' if x > 0.3 else 'F')))))
    )
    
    # íˆ¬ì ì„ í˜¸ë„ë„ 0~1 ë²”ìœ„ì— ë§ê²Œ ì¡°ì •
    equity_df['Investment_Preference'] = equity_df['Sentiment_Score'].apply(
        lambda x: 'Strong Buy' if x > 0.7 else (
                  'Buy' if x > 0.6 else (
                  'Hold' if x > 0.5 else (
                  'Caution' if x > 0.4 else 'Avoid')))
    )
    
    return equity_df.sort_values('Portfolio_Score', ascending=False)

# ======================== ì‹œê°í™” í•¨ìˆ˜ ========================

def plot_sentiment_distribution(df):
    """ì„¼í‹°ë¨¼íŠ¸ ë¶„í¬ ì‹œê°í™”"""
    sentiment_counts = df['Sentiment'].value_counts()
    
    colors = {
        'POSITIVE': '#28a745',
        'NEGATIVE': '#dc3545',
        'NEUTRAL': '#6c757d'
    }
    
    fig = go.Figure(data=[
        go.Bar(
            x=sentiment_counts.index,
            y=sentiment_counts.values,
            marker=dict(color=[colors.get(x, '#6c757d') for x in sentiment_counts.index]),
            text=sentiment_counts.values,
            textposition='auto',
        )
    ])
    
    fig.update_layout(
        title="ì „ì²´ ì„¼í‹°ë¨¼íŠ¸ ë¶„í¬",
        xaxis_title="ì„¼í‹°ë¨¼íŠ¸ ë¶„ë¥˜",
        yaxis_title="ì¢…ëª©ìˆ˜",
        template="plotly_white",
        height=400
    )
    
    return fig

def plot_equity_sentiment_scores(df):
    """ì¢…ëª©ë³„ ì„¼í‹°ë¨¼íŠ¸ ì ìˆ˜ ì‹œê°í™” (ê°œì„  ë²„ì „)"""
    df_sorted = df.sort_values('Sentiment_Score', ascending=False)
    
    # ì„¼í‹°ë¨¼íŠ¸ì™€ ì ìˆ˜ë¥¼ í•¨ê»˜ í‘œì‹œí•˜ëŠ” í…ìŠ¤íŠ¸ ìƒì„±
    hover_text = df_sorted.apply(
        lambda row: f"{row['Equity']}<br>"
                   f"ì„¼í‹°ë¨¼íŠ¸: {row['Sentiment']}<br>"
                   f"í™•ì‹ ë„: {row['Sentiment_Score']:.3f}<br>"
                   f"(AIê°€ ì´ ì¢…ëª©ì„ '{row['Sentiment']}'ë¡œ {row['Sentiment_Score']:.1%} í™•ì‹ )",
        axis=1
    )
    
    # ì„¼í‹°ë¨¼íŠ¸ì— ë”°ë¼ ìƒ‰ìƒ ì§€ì •
    colors = df_sorted['Sentiment'].map({
        'POSITIVE': '#28a745',
        'NEGATIVE': '#dc3545',
        'NEUTRAL': '#6c757d'
    })
    
    fig = go.Figure(data=[
        go.Bar(
            x=df_sorted['Equity'],
            y=df_sorted['Sentiment_Score'],
            marker=dict(color=colors),
            text=[f"{s}<br>({row['Sentiment']})" 
                  for s, row in zip(df_sorted['Sentiment_Score'].round(3), df_sorted.iterrows())],
            textposition='auto',
            hovertext=hover_text,
            hoverinfo='text',
        )
    ])
    
    fig.update_layout(
        title="ì¢…ëª©ë³„ AI ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ê²°ê³¼<br><sub>ë†’ì„ìˆ˜ë¡ AIê°€ í•´ë‹¹ ë¶„ë¥˜ì— ëŒ€í•´ í™•ì‹  | ì´ˆë¡=ê¸ì •, íšŒìƒ‰=ì¤‘ë¦½, ë¹¨ê°•=ë¶€ì •</sub>",
        xaxis_title="ì¢…ëª©",
        yaxis_title="í™•ì‹ ë„ (0~1)",
        template="plotly_white",
        height=500,
        showlegend=False,
        yaxis=dict(range=[0, 1])
    )
    
    # ë²”ë¡€ ì—­í• ì„ í•˜ëŠ” ì£¼ì„ ì¶”ê°€
    fig.add_annotation(
        text="<b>ìƒ‰ìƒ ì„¤ëª…:</b><br>ğŸŸ¢ ê¸ì •(POSITIVE) | âš« ì¤‘ë¦½(NEUTRAL) | ğŸ”´ ë¶€ì •(NEGATIVE)",
        xref="paper", yref="paper",
        x=0.5, y=1.15,
        showarrow=False,
        font=dict(size=12),
        bgcolor="rgba(255,255,255,0.8)",
        bordercolor="#333",
        borderwidth=1
    )
    
    return fig


def extract_sentiment_contributing_words(text, sentiment_pipeline, target_sentiment, top_n=100):
    """
    SHAPì„ ì‚¬ìš©í•˜ì—¬ ì„¼í‹°ë¨¼íŠ¸ì— ì‹¤ì œë¡œ ê¸°ì—¬í•œ ë‹¨ì–´ ì¶”ì¶œ
    
    Args:
        text: ë¶„ì„í•  í…ìŠ¤íŠ¸
        sentiment_pipeline: ì„¼í‹°ë¨¼íŠ¸ íŒŒì´í”„ë¼ì¸
        target_sentiment: 'POSITIVE', 'NEGATIVE', 'NEUTRAL'
        top_n: ì¶”ì¶œí•  ìƒìœ„ ë‹¨ì–´ ìˆ˜
    
    Returns:
        dict: {ë‹¨ì–´: ê¸°ì—¬ë„ ì ìˆ˜}
    """
    if not text or len(text.strip()) < 10:
        return {}
    
    # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ì²­í‚¹
    text = preprocess_text(text)
    chunks = chunk_text(text, max_length=512)
    
    # ê° ì²­í¬ì—ì„œ ê¸°ì—¬ë„ ë†’ì€ ë‹¨ì–´ ì¶”ì¶œ
    word_contributions = {}
    
    model = sentiment_pipeline.model
    tokenizer = sentiment_pipeline.tokenizer
    
    # ì„¼í‹°ë¨¼íŠ¸ ë ˆì´ë¸” ë§¤í•‘
    sentiment_map = {
        'POSITIVE': ['positive', 'POSITIVE'],
        'NEGATIVE': ['negative', 'NEGATIVE'],
        'NEUTRAL': ['neutral', 'NEUTRAL']
    }
    
    for chunk in chunks[:5]:  # ì²˜ë¦¬ ì‹œê°„ì„ ìœ„í•´ ìµœëŒ€ 5ê°œ ì²­í¬ë§Œ
        try:
            # í† í°í™”
            inputs = tokenizer(chunk, return_tensors="pt", truncation=True, max_length=512)
            
            # ëª¨ë¸ ì˜ˆì¸¡
            outputs = model(**inputs)
            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
            
            # í•´ë‹¹ ì„¼í‹°ë¨¼íŠ¸ì˜ í™•ë¥ 
            predicted_label = sentiment_pipeline(chunk, truncation=True, max_length=512)[0]['label']
            
            # íƒ€ê²Ÿ ì„¼í‹°ë¨¼íŠ¸ê°€ ì•„ë‹ˆë©´ ìŠ¤í‚µ
            if predicted_label not in sentiment_map[target_sentiment]:
                continue
            
            # SHAP ê°’ ê³„ì‚° (ê°„ì†Œí™” ë²„ì „: attention weights ì‚¬ìš©)
            tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])
            
            # Attention weightsë¥¼ ê¸°ì—¬ë„ ê·¼ì‚¬ì¹˜ë¡œ ì‚¬ìš©
            with torch.no_grad():
                attention = model(**inputs, output_attentions=True).attentions
                # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ attention í‰ê· 
                avg_attention = attention[-1].mean(dim=1).squeeze().mean(dim=0)
            
            # í† í°ë³„ ê¸°ì—¬ë„ ì§‘ê³„
            for token, weight in zip(tokens, avg_attention):
                # íŠ¹ìˆ˜ í† í° ë° ì„œë¸Œì›Œë“œ ì²˜ë¦¬
                if token.startswith('##'):
                    token = token[2:]
                elif token in ['[CLS]', '[SEP]', '[PAD]']:
                    continue
                
                token = token.lower().strip()
                
                # stop words í•„í„°ë§
                stop_words = {
                    'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
                    'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
                    'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
                    'should', 'may', 'might', 'must', 'can', 'that', 'this', 'as', 'if',
                    'it', 'its', 'which', 'who', 'what', 'when', 'where', 'why', 'how',
                    'thank', 'thanks', 'think', 'year'
                }
                
                if token in stop_words or len(token) < 3:
                    continue
                
                # ê¸°ì—¬ë„ ëˆ„ì 
                if token in word_contributions:
                    word_contributions[token] += float(weight)
                else:
                    word_contributions[token] = float(weight)
        
        except Exception as e:
            continue
    
    # ìƒìœ„ Nê°œ ë‹¨ì–´ ë°˜í™˜
    sorted_words = sorted(word_contributions.items(), key=lambda x: x[1], reverse=True)
    return dict(sorted_words[:top_n])

def plot_sentiment_wordcloud(text, sentiment, sentiment_pipeline, title="ì„¼í‹°ë¨¼íŠ¸ ê¸°ì—¬ ì›Œë“œí´ë¼ìš°ë“œ"):
    """ì„¼í‹°ë¨¼íŠ¸ ê¸°ì—¬ë„ ê¸°ë°˜ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±"""
    if not text or len(text.strip()) < 10:
        return None
    
    # ì„¼í‹°ë¨¼íŠ¸ì— ê¸°ì—¬í•œ ë‹¨ì–´ ì¶”ì¶œ
    word_scores = extract_sentiment_contributing_words(text, sentiment_pipeline, sentiment, top_n=100)
    
    if not word_scores:
        return None
    
    # WordCloud ìƒì„± (ë¹ˆë„ìˆ˜ ëŒ€ì‹  ê¸°ì—¬ë„ ì‚¬ìš©)
    wordcloud = WordCloud(
        width=800,
        height=400,
        background_color='white',
        colormap='RdYlGn' if sentiment == 'POSITIVE' else ('Reds_r' if sentiment == 'NEGATIVE' else 'Blues'),
        max_words=80,
        relative_scaling=0.5,
        min_font_size=10
    ).generate_from_frequencies(word_scores)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    ax.set_title(title, fontsize=16, fontweight='bold')
    
    return fig

def plot_wordcloud(text, title="ì›Œë“œí´ë¼ìš°ë“œ"):
    """ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±"""
    if not text or len(text.strip()) < 10:
        return None
    
    wordcloud = WordCloud(
        width=800,
        height=400,
        background_color='white',
        colormap='viridis',
        max_words=100,
        relative_scaling=0.5,
        min_font_size=10
    ).generate(text)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    ax.set_title(title, fontsize=16, fontweight='bold')
    
    return fig

def plot_document_length_analysis(df):
    """ë¬¸ì„œ ê¸¸ì´ ë¶„ì„"""
    df['Text_Length'] = df['Combined_Text'].str.len()
    
    fig = px.scatter(
        df,
        x='Text_Length',
        y='Sentiment_Score',
        color='Sentiment',
        size='Text_Length',
        hover_data=['Equity'],
        title="ë¬¸ì„œ ê¸¸ì´ vs ì„¼í‹°ë¨¼íŠ¸",
        labels={'Text_Length': 'ë¬¸ì„œ ê¸¸ì´ (ë¬¸ì ìˆ˜)', 'Sentiment_Score': 'ì„¼í‹°ë¨¼íŠ¸'},
        color_discrete_map={'POSITIVE': '#28a745', 'NEGATIVE': '#dc3545', 'NEUTRAL': '#6c757d'}
    )
    
    fig.update_layout(height=400, template="plotly_white")
    return fig

def plot_sentiment_score_distribution(df):
    """ì„¼í‹°ë¨¼íŠ¸ í™•ì‹ ë„ ë¶„í¬"""
    fig = go.Figure()
    
    # ì„¼í‹°ë¨¼íŠ¸ë³„ë¡œ íˆìŠ¤í† ê·¸ë¨ ìƒì„±
    for sentiment, color in [('POSITIVE', '#28a745'), ('NEGATIVE', '#dc3545'), ('NEUTRAL', '#6c757d')]:
        sentiment_data = df[df['Sentiment'] == sentiment]['Sentiment_Score']
        if len(sentiment_data) > 0:
            fig.add_trace(go.Histogram(
                x=sentiment_data,
                name=sentiment,
                marker_color=color,
                opacity=0.6,
                nbinsx=20
            ))
    
    fig.add_vline(x=0.5, line_dash="dash", line_color="gray", opacity=0.5,
                  annotation_text="ì¤‘ê°„ê°’ (0.5)")
    
    fig.update_layout(
        title="ì„¼í‹°ë¨¼íŠ¸ë³„ í™•ì‹ ë„ ë¶„í¬<br><sub>AIê°€ ê° ì„¼í‹°ë¨¼íŠ¸ë¥¼ ì–¼ë§ˆë‚˜ í™•ì‹ í–ˆëŠ”ì§€</sub>",
        xaxis_title="í™•ì‹ ë„ (0~1)",
        yaxis_title="ì¢…ëª©ìˆ˜",
        template="plotly_white",
        height=400,
        barmode='overlay',
        showlegend=True,
        xaxis=dict(range=[0, 1])
    )
    
    return fig

def plot_sentiment_comparison_radar(df):
    """ì„¼í‹°ë¨¼íŠ¸ ìƒì„¸ ë¶„ì„ ì°¨íŠ¸ (ê°œì„  ë²„ì „)"""
    top10 = df.nlargest(10, 'Sentiment_Score')
    
    # ì„¼í‹°ë¨¼íŠ¸ë³„ ìƒ‰ìƒ
    colors = top10['Sentiment'].map({
        'POSITIVE': '#28a745',
        'NEGATIVE': '#dc3545',
        'NEUTRAL': '#6c757d'
    })
    
    fig = go.Figure(data=[
        go.Bar(
            x=top10['Equity'],
            y=top10['Sentiment_Score'],
            marker=dict(color=colors),
            text=[f"{score:.3f}<br>({sent})" 
                  for score, sent in zip(top10['Sentiment_Score'], top10['Sentiment'])],
            textposition='auto',
        )
    ])
    
    fig.update_layout(
        title="í™•ì‹ ë„ ìƒìœ„ 10ê°œ ì¢…ëª©<br><sub>AIê°€ ìì‹ ì˜ íŒë‹¨ì„ ê°€ì¥ í™•ì‹ í•˜ëŠ” ì¢…ëª©ë“¤</sub>",
        xaxis_title="ì¢…ëª©",
        yaxis_title="í™•ì‹ ë„",
        template="plotly_white",
        height=500,
        yaxis=dict(range=[0, 1])
    )
    
    return fig

# ======================== Streamlit ë©”ì¸ ì•± ========================

def main():
    st.title("ğŸ“Š Portfolio Sentiment Analysis")
    st.markdown("Transformer ê¸°ë°˜ í…ìŠ¤íŠ¸ ì„¼í‹°ë¨¼íŠ¸")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.markdown("## âš™ï¸ ì„¤ì •")
    
    uploaded_file = st.sidebar.file_uploader(
        "CSV íŒŒì¼ ì—…ë¡œë“œ",
        type=['csv'],
        help="Document Title, Date, Equity, 0-6 ì—´ì„ í¬í•¨í•œ CSV íŒŒì¼"
    )
    
    analyze_button = st.sidebar.button("ğŸ“ˆ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ì‹¤í–‰", key="analyze_main")
    
    if uploaded_file is not None:
        # íŒŒì¼ ë¡œë“œ
        df = pd.read_csv(uploaded_file)
        
        st.sidebar.success("âœ… íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
        st.sidebar.markdown("---")
        
        # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
        with st.sidebar.expander("ğŸ“‹ ë°ì´í„° ì •ë³´"):
            st.write(f"ì´ í–‰ ìˆ˜: {len(df)}")
            st.write(f"ì´ ì¢…ëª© ìˆ˜: {df['Equity'].nunique()}")
            st.write(f"ì»¬ëŸ¼: {', '.join(df.columns.tolist())}")
        
        if analyze_button:
            st.session_state.analysis_complete = False
            
            with st.spinner("ğŸ”„ ëª¨ë¸ ë¡œë“œ ì¤‘..."):
                sentiment_pipeline, model_name = load_sentiment_model()
                st.session_state.sentiment_pipeline = sentiment_pipeline
            
            st.info(f"âœ… ëª¨ë¸: {model_name}")
            
            with st.spinner("â³ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ì§„í–‰ ì¤‘..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # ì¢…ëª©ë³„ë¡œ í…ìŠ¤íŠ¸ í†µí•© ë° ë¶„ì„
                text_columns = [str(i) for i in range(7) if str(i) in df.columns]
                
                # ì¢…ëª©ë³„ë¡œ ê·¸ë£¹í™”
                equity_groups = df.groupby('Equity')
                
                results = []
                total_equities = len(equity_groups)
                
                for idx, (equity, group) in enumerate(equity_groups):
                    # ë™ì¼ Document Titleì´ ìˆëŠ” ê²½ìš° í‰ê·  ê³„ì‚°
                    doc_results = []
                    
                    for doc_title in group['Document Title'].unique():
                        doc_rows = group[group['Document Title'] == doc_title]
                        
                        # ëª¨ë“  í…ìŠ¤íŠ¸ ì—´ í†µí•©
                        combined_text = ' '.join(
                            doc_rows[text_columns].fillna('').astype(str).values.flatten()
                        )
                        
                        sentiment, score = analyze_sentiment_for_equity(combined_text, sentiment_pipeline)
                        doc_results.append({
                            'sentiment': sentiment,
                            'score': score,
                            'text': combined_text
                        })
                    
                    # ë™ì¼ ì¢…ëª©ì˜ ì—¬ëŸ¬ Document í‰ê· 
                    avg_score = np.mean([r['score'] for r in doc_results])

                    # AIê°€ ë¶„ë¥˜í•œ ì„¼í‹°ë¨¼íŠ¸ë¥¼ ë‹¤ìˆ˜ê²°ë¡œ ê²°ì •
                    sentiments = [r['sentiment'] for r in doc_results]
                    from collections import Counter
                    sentiment_counts = Counter(sentiments)
                    final_sentiment = sentiment_counts.most_common(1)[0][0]
                    
                    # ëª¨ë“  í…ìŠ¤íŠ¸ í†µí•© (ì›Œë“œí´ë¼ìš°ë“œìš©)
                    all_text = ' '.join([r['text'] for r in doc_results])
                    
                    results.append({
                        'Equity': equity,
                        'Sentiment': final_sentiment,
                        'Sentiment_Score': avg_score,
                        'Document_Count': len(doc_results),
                        'Combined_Text': all_text
                    })
                    
                    progress_bar.progress((idx + 1) / total_equities)
                    status_text.text(f"ë¶„ì„ ì¤‘: {equity} ({idx + 1}/{total_equities})")
                
                result_df = pd.DataFrame(results)
                
                progress_bar.progress(100)
                status_text.text("âœ… ë¶„ì„ ì™„ë£Œ!")
            
            st.session_state.analysis_complete = True
            st.session_state.analysis_df = result_df
        
        if st.session_state.analysis_complete:
            df = st.session_state.analysis_df
            
            st.success("âœ… ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ì™„ë£Œ!")
            
            # ==================== ë©”íŠ¸ë¦­ ëŒ€ì‹œë³´ë“œ ====================
            st.markdown("---")
            st.subheader("ğŸ“Š ì£¼ìš” ë©”íŠ¸ë¦­")
            
            sentiment_counts = df['Sentiment'].value_counts()
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "ê¸ì •ì  ì¢…ëª©",
                    f"{sentiment_counts.get('POSITIVE', 0)}ê°œ",
                    f"{sentiment_counts.get('POSITIVE', 0) / len(df) * 100:.1f}%"
                )
            
            with col2:
                st.metric(
                    "ë¶€ì •ì  ì¢…ëª©",
                    f"{sentiment_counts.get('NEGATIVE', 0)}ê°œ",
                    f"{sentiment_counts.get('NEGATIVE', 0) / len(df) * 100:.1f}%"
                )
            
            with col3:
                st.metric(
                    "ì¤‘ë¦½ì  ì¢…ëª©",
                    f"{sentiment_counts.get('NEUTRAL', 0)}ê°œ",
                    f"{sentiment_counts.get('NEUTRAL', 0) / len(df) * 100:.1f}%"
                )
            
            with col4:
                top_equity = df.nlargest(1, 'Sentiment_Score').iloc[0]
                st.metric(
                    "ìµœê³  ì„ í˜¸ ì¢…ëª©",
                    top_equity['Equity'],
                    f"{top_equity['Sentiment_Score']:.3f}"
                )
            
            # Top 5 ì¢…ëª© í‘œì‹œ
            st.markdown("### ğŸ† ì„¼í‹°ë¨¼íŠ¸ Top 5")
            top5 = df.nlargest(5, 'Sentiment_Score')[['Equity', 'Sentiment_Score', 'Sentiment']]
            
            cols = st.columns(5)
            for idx, (_, row) in enumerate(top5.iterrows()):
                with cols[idx]:
                    st.markdown(f"**#{idx+1} {row['Equity']}**")
                    st.markdown(f"<p class='{row['Sentiment'].lower()}'>{row['Sentiment_Score']:.3f}</p>", 
                               unsafe_allow_html=True)
            
            # ==================== ì‹œê°í™” ====================
            st.markdown("---")
            st.subheader("ğŸ“ˆ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ìƒì„¸")
            
            tab1, tab2, tab3, tab4, tab5 = st.tabs([
                "ì„¼í‹°ë¨¼íŠ¸ ë¶„í¬", "ì¢…ëª© ì ìˆ˜", "ì›Œë“œí´ë¼ìš°ë“œ", "ë¬¸ì„œ ë¶„ì„", "ìƒì„¸ ë¶„ì„"
            ])
            
            with tab1:
                st.plotly_chart(plot_sentiment_distribution(df), width="stretch")
                st.plotly_chart(plot_sentiment_score_distribution(df), width="stretch")
            
            with tab2:
                st.plotly_chart(plot_equity_sentiment_scores(df), width="stretch")
                st.plotly_chart(plot_sentiment_comparison_radar(df), width="stretch")
                
                # ê°ì • ë¶„ë¥˜ ê¸°ì¤€ ì„¤ëª… ì¶”ê°€
                st.info("""
                **ğŸ“Œ AI ê¸°ë°˜ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ë°©ì‹**

                **ìƒ‰ìƒ = AIê°€ ë¶„ë¥˜í•œ ì„¼í‹°ë¨¼íŠ¸**
                - ğŸŸ¢ **ì´ˆë¡ìƒ‰**: AIê°€ "ê¸ì •(POSITIVE)"ìœ¼ë¡œ íŒë‹¨í•œ ì¢…ëª©
                - âš« **íšŒìƒ‰**: AIê°€ "ì¤‘ë¦½(NEUTRAL)"ë¡œ íŒë‹¨í•œ ì¢…ëª©  
                - ğŸ”´ **ë¹¨ê°„ìƒ‰**: AIê°€ "ë¶€ì •(NEGATIVE)"ë¡œ íŒë‹¨í•œ ì¢…ëª©

                **ì ìˆ˜ ì˜ë¯¸ (0~1 ë²”ìœ„)**:
                - ì ìˆ˜ëŠ” AIê°€ í•´ë‹¹ ì„¼í‹°ë¨¼íŠ¸ì— ëŒ€í•´ ì–¼ë§ˆë‚˜ í™•ì‹ í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤
                - 0.8 ì´ìƒ: ë§¤ìš° ê°•í•œ í™•ì‹ 
                - 0.6~0.8: ê°•í•œ í™•ì‹ 
                - 0.5~0.6: ì¤‘ê°„ í™•ì‹ 
                - 0.5 ë¯¸ë§Œ: ì•½í•œ í™•ì‹ 
    
                **ë¶„ë¥˜ ë°©ë²•**:
                - FinBERTê°€ ì „ì²´ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ POSITIVE/NEGATIVE/NEUTRAL ì¤‘ ê°€ì¥ í™•ì‹ í•˜ëŠ” ê²ƒì„ ì„ íƒ
                - ì‚¬ëŒì´ ì •í•œ ì„ê³„ê°’ì´ ì•„ë‹Œ, AIì˜ ìˆœìˆ˜í•œ íŒë‹¨ì„ 100% ë°˜ì˜
                - ê° ì²­í¬ì˜ ì‹ ë¢°ë„ë¥¼ ëˆ„ì í•˜ì—¬ ìµœì¢… ê²°ì •
    
                **ğŸ’¡ ì™œ ì´ ë°©ì‹ì´ ë” ë‚˜ì€ê°€?**
                ê¸ˆìœµ ì „ë¬¸ AI ëª¨ë¸(FinBERT)ì€ ìˆ˜ë°±ë§Œ ê°œì˜ ê¸ˆìœµ ë¬¸ì„œë¡œ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤.
                """)

                # êµ¬ì²´ì ì¸ ì˜ˆì‹œ ì¶”ê°€
                st.markdown("### ğŸ“Š ì‹¤ì „ ì˜ˆì‹œ")
    
                example_positive = df[df['Sentiment'] == 'POSITIVE'].nlargest(1, 'Sentiment_Score')
                example_neutral = df[df['Sentiment'] == 'NEUTRAL'].nlargest(1, 'Sentiment_Score') if 'NEUTRAL' in df['Sentiment'].values else None
    
                cols = st.columns(2)
                with cols[0]:
                    if not example_positive.empty:
                        row = example_positive.iloc[0]
                        st.success(f"""
                        **âœ… ê¸ì • ì˜ˆì‹œ: {row['Equity']}**
                        - ì„¼í‹°ë¨¼íŠ¸: POSITIVE (ê¸ì •)
                        - í™•ì‹ ë„: {row['Sentiment_Score']:.3f}
                        - í•´ì„: AIê°€ ì´ ì¢…ëª©ì˜ ë¬¸ì„œë¥¼ ë¶„ì„í•œ ê²°ê³¼, {row['Sentiment_Score']*100:.1f}%ì˜ í™•ì‹ ìœ¼ë¡œ "ê¸ì •ì "ì´ë¼ê³  íŒë‹¨í–ˆìŠµë‹ˆë‹¤.
                        """)
                        
                with cols[1]:
                    if example_neutral is not None and not example_neutral.empty:
                        row = example_neutral.iloc[0]
                        st.warning(f"""
                        **âš ï¸ ì¤‘ë¦½ ì˜ˆì‹œ: {row['Equity']}**
                        - ì„¼í‹°ë¨¼íŠ¸: NEUTRAL (ì¤‘ë¦½)
                        - í™•ì‹ ë„: {row['Sentiment_Score']:.3f}
                        - í•´ì„: AIê°€ ì´ ì¢…ëª©ì˜ ë¬¸ì„œì—ì„œ ê¸ì •ë„ ë¶€ì •ë„ ì•„ë‹Œ ì¤‘ë¦½ì ì¸ ë‚´ìš©ì„ {row['Sentiment_Score']*100:.1f}% í™•ì‹ ìœ¼ë¡œ íŒë‹¨í–ˆìŠµë‹ˆë‹¤.
                        """)                
            
            with tab3:
                sentiment_pipeline = st.session_state.get('sentiment_pipeline')  # ì´ ì¤„ ì¶”ê°€
                st.markdown("### ì›Œë“œí´ë¼ìš°ë“œ ë¶„ì„")
    
                # ë¶„ì„ ëª¨ë“œ ì„ íƒ
                analysis_mode = st.radio(
                    "ë¶„ì„ ëª¨ë“œ ì„ íƒ",
                    options=["ë¹ˆë„ ê¸°ë°˜ (ê¸°ë³¸)", "ì„¼í‹°ë¨¼íŠ¸ ê¸°ì—¬ë„ ê¸°ë°˜ (AI)"],
                    horizontal=True,
                    help="ê¸°ì—¬ë„ ê¸°ë°˜: ì‹¤ì œë¡œ ì„¼í‹°ë¨¼íŠ¸ ë¶„ë¥˜ì— ì˜í–¥ì„ ì¤€ ë‹¨ì–´ë§Œ í‘œì‹œ (ì²˜ë¦¬ ì‹œê°„ ë” ì†Œìš”)"
                )
    
                wc_option = st.radio(
                    "ì›Œë“œí´ë¼ìš°ë“œ ìœ í˜• ì„ íƒ",
                    options=["ì„¼í‹°ë¨¼íŠ¸ë³„", "ì¢…ëª©ë³„"],
                    horizontal=True
                )
    
                if analysis_mode == "ë¹ˆë„ ê¸°ë°˜ (ê¸°ë³¸)":
                    # ê¸°ì¡´ ì½”ë“œ ìœ ì§€
                    if wc_option == "ì„¼í‹°ë¨¼íŠ¸ë³„":
                        sentiment_filter = st.selectbox(
                            "ì„¼í‹°ë¨¼íŠ¸ ì„ íƒ",
                            options=["ì „ì²´"] + df['Sentiment'].unique().tolist()
                        )
            
                        if sentiment_filter == "ì „ì²´":
                            text_data = ' '.join(df['Combined_Text'].tolist())
                            title = "All Word Cloud"
                        else:
                            text_data = ' '.join(df[df['Sentiment'] == sentiment_filter]['Combined_Text'].tolist())
                            title = f"{sentiment_filter} Word Cloud"
            
                        wordcloud_fig = plot_wordcloud(text_data, title)
                        if wordcloud_fig:
                            st.pyplot(wordcloud_fig, use_container_width=True)
                        else:
                            st.warning("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
                    else:  # ì¢…ëª©ë³„
                        equity_filter = st.selectbox(
                            "ì¢…ëª© ì„ íƒ",
                            options=df['Equity'].tolist()
                        )
            
                        text_data = df[df['Equity'] == equity_filter]['Combined_Text'].iloc[0]
                        title = f"{equity_filter} Word Cloud"
            
                        wordcloud_fig = plot_wordcloud(text_data, title)
                        if wordcloud_fig:
                            st.pyplot(wordcloud_fig, use_container_width=True)
                        else:
                            st.warning("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
                else:  # ì„¼í‹°ë¨¼íŠ¸ ê¸°ì—¬ë„ ê¸°ë°˜
        
                    if wc_option == "ì„¼í‹°ë¨¼íŠ¸ë³„":
                        sentiment_filter = st.selectbox(
                            "ì„¼í‹°ë¨¼íŠ¸ ì„ íƒ",
                            options=df['Sentiment'].unique().tolist(),
                            key="sentiment_contrib"
                        )
            
                        text_data = ' '.join(df[df['Sentiment'] == sentiment_filter]['Combined_Text'].tolist())
                        title = f"{sentiment_filter} - ì„¼í‹°ë¨¼íŠ¸ ê¸°ì—¬ ë‹¨ì–´"
            
                        with st.spinner("ë¶„ì„ ì¤‘..."):
                            wordcloud_fig = plot_sentiment_wordcloud(
                                text_data, 
                                sentiment_filter, 
                                sentiment_pipeline,
                                title
                            )
            
                        if wordcloud_fig:
                            st.pyplot(wordcloud_fig, use_container_width=True)
                            st.caption("ğŸ’¡ ë‹¨ì–´ í¬ê¸° = í•´ë‹¹ ì„¼í‹°ë¨¼íŠ¸ ë¶„ë¥˜ì— ëŒ€í•œ AI ëª¨ë¸ì˜ ê¸°ì—¬ë„")
                        else:
                            st.warning("ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
                    else:  # ì¢…ëª©ë³„
                        equity_filter = st.selectbox(
                            "ì¢…ëª© ì„ íƒ",
                            options=df['Equity'].tolist(),
                            key="equity_contrib"
                        )
            
                        equity_data = df[df['Equity'] == equity_filter].iloc[0]
                        text_data = equity_data['Combined_Text']
                        sentiment = equity_data['Sentiment']
                        title = f"{equity_filter} - {sentiment} (Contribution Based)"
            
                        with st.spinner("ë¶„ì„ ì¤‘..."):
                            wordcloud_fig = plot_sentiment_wordcloud(
                                text_data,
                                sentiment,
                                sentiment_pipeline,
                                title
                            )
            
                        if wordcloud_fig:
                            st.pyplot(wordcloud_fig, use_container_width=True)
                            st.caption("ğŸ’¡ ì´ ì¢…ëª©ì´ í•´ë‹¹ ì„¼í‹°ë¨¼íŠ¸ë¡œ ë¶„ë¥˜ëœ ì´ìœ ê°€ ë˜ëŠ” í•µì‹¬ ë‹¨ì–´ë“¤ì…ë‹ˆë‹¤.")
                        else:
                            st.warning("ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            with tab4:
                st.plotly_chart(plot_document_length_analysis(df), width="stretch")
                
                # í†µê³„ ìš”ì•½
                st.markdown("### ğŸ“Š ë¬¸ì„œ í†µê³„")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("í‰ê·  ë¬¸ì„œ ê¸¸ì´", f"{df['Combined_Text'].str.len().mean():.0f} ì")
                with col2:
                    st.metric("ìµœëŒ€ ë¬¸ì„œ ê¸¸ì´", f"{df['Combined_Text'].str.len().max():.0f} ì")
                with col3:
                    st.metric("ìµœì†Œ ë¬¸ì„œ ê¸¸ì´", f"{df['Combined_Text'].str.len().min():.0f} ì")
            
            with tab5:
                st.markdown("### ğŸ“‹ ìƒì„¸ ë¶„ì„")
                
                # ì¢…ëª©ë³„ ìˆœìœ„
                equity_ranking = calculate_equity_ranking(df)
                
                st.markdown("#### ğŸ† ì¢…ëª© ìˆœìœ„ ë° í¬íŠ¸í´ë¦¬ì˜¤ í‰ê°€")
                st.caption("""
                ğŸ’¡ **í…Œì´ë¸” ì„¤ëª…**: 
                - ì„¼í‹°ë¨¼íŠ¸ ì—´ = AIì˜ í™•ì‹ ë„ (ë†’ì„ìˆ˜ë¡ í•´ë‹¹ ë¶„ë¥˜ì— í™•ì‹ )
                - ì„¼í‹°ë¨¼íŠ¸ ë¶„ë¥˜ = AIê°€ íŒë‹¨í•œ ê¸ì •/ì¤‘ë¦½/ë¶€ì •
                - ë“±ê¸‰ = í™•ì‹ ë„ ê¸°ë°˜ ìë™ ë“±ê¸‰ (ì°¸ê³ ìš©)
                - íˆ¬ìì„ í˜¸ë„ = í™•ì‹ ë„ì™€ ì„¼í‹°ë¨¼íŠ¸ ì¡°í•© (ì°¸ê³ ìš©)
                """)
                
                display_ranking = equity_ranking[['Equity', 'Sentiment_Score', 'Sentiment', 
                                                  'Document_Count', 'Sentiment_Grade', 
                                                  'Investment_Preference']].copy()
                display_ranking.columns = ['ì¢…ëª©', 'ì„¼í‹°ë¨¼íŠ¸', 'ì„¼í‹°ë¨¼íŠ¸ ë¶„ë¥˜', 'ë¬¸ì„œìˆ˜', 'ë“±ê¸‰', 'íˆ¬ìì„ í˜¸ë„']
                display_ranking = display_ranking.round(4)
                
                st.dataframe(
                    display_ranking,
                    use_container_width=True,
                    height=400
                )
                
                # ì¢…ëª©ë³„ í‚¤ì›Œë“œ
                st.markdown("#### ğŸ” ì¢…ëª©ë³„ ì£¼ìš” í‚¤ì›Œë“œ")
                
                selected_equity = st.selectbox("ì¢…ëª© ì„ íƒ", df['Equity'].tolist(), key="keyword_equity")
                
                equity_text = df[df['Equity'] == selected_equity]['Combined_Text'].iloc[0]
                keywords = extract_keywords(equity_text, n_words=20)
                
                if keywords:
                    keyword_df = pd.DataFrame(keywords, columns=['í‚¤ì›Œë“œ', 'ë¹ˆë„'])
                    
                    fig = px.bar(
                        keyword_df.head(15),
                        x='ë¹ˆë„',
                        y='í‚¤ì›Œë“œ',
                        orientation='h',
                        title=f"{selected_equity} - ì£¼ìš” í‚¤ì›Œë“œ Top 15",
                        color='ë¹ˆë„',
                        color_continuous_scale='Viridis'
                    )
                    fig.update_layout(height=500)
                    st.plotly_chart(fig, width="stretch")
                else:
                    st.info("ì¶”ì¶œí•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # ê°ì •ë³„ í†µê³„
                st.markdown("#### ğŸ’­ ê°ì • ë¶„ë¥˜ë³„ í†µê³„")
                
                sentiment_stats = df.groupby('Sentiment').agg({
                    'Equity': 'count',
                    'Sentiment_Score': ['mean', 'std', 'min', 'max']
                }).round(4)
                
                sentiment_stats.columns = ['ì¢…ëª©ìˆ˜', 'í‰ê· ì ìˆ˜', 'í‘œì¤€í¸ì°¨', 'ìµœì†Œ', 'ìµœëŒ€']
                st.dataframe(sentiment_stats, use_container_width=True)


            # ==================== ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ ====================
            st.markdown("---")
            st.subheader("ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # ë¶„ì„ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ
                result_csv = df[['Equity', 'Sentiment', 'Sentiment_Score', 'Document_Count']].to_csv(index=False)
                st.download_button(
                    label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ (CSV)",
                    data=result_csv,
                    file_name=f"sentiment_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
            
            with col2:
                # ì¢…ëª© ìˆœìœ„ ë‹¤ìš´ë¡œë“œ
                equity_ranking = calculate_equity_ranking(df)
                ranking_csv = equity_ranking.to_csv()
                st.download_button(
                    label="ğŸ“Š ì¢…ëª© ìˆœìœ„ (CSV)",
                    data=ranking_csv,
                    file_name=f"equity_ranking_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )
    
    else:
        st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        
        st.markdown("---")
        st.subheader("ğŸ“ ì‚¬ìš© ë°©ë²•")
        st.markdown("""
        1. **íŒŒì¼ ì—…ë¡œë“œ**: CSV íŒŒì¼ì„ ì—…ë¡œë“œí•©ë‹ˆë‹¤
           - í•„ìˆ˜ ì—´: Document Title, Date, Equity
           - í…ìŠ¤íŠ¸ ì—´: 0, 1, 2, 3, 4, 5, 6 (ìë™ìœ¼ë¡œ í†µí•©ë©ë‹ˆë‹¤)
        
        2. **ë¶„ì„ ì‹¤í–‰**: "ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„ ì‹¤í–‰" ë²„íŠ¼ì„ í´ë¦­í•©ë‹ˆë‹¤
           - ìµœì‹  Transformer ëª¨ë¸ (FinBERT) ì‚¬ìš©
           - ê¸ˆìœµ ë„ë©”ì¸ì— ìµœì í™”ëœ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„
        
        3. **ê²°ê³¼ í™•ì¸**: 
           - ğŸ“Š ì„¼í‹°ë¨¼íŠ¸ ë¶„í¬ ë° ì‹œê°í™”
           - ğŸ† ì¢…ëª©ë³„ ìˆœìœ„ ë° í¬íŠ¸í´ë¦¬ì˜¤ ì ìˆ˜
           - ğŸ” ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„
           - ğŸ’­ ì„¼í‹°ë¨¼íŠ¸ë³„ ìƒì„¸ í†µê³„
        
        4. **ê²°ê³¼ ë‹¤ìš´ë¡œë“œ**: ë¶„ì„ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤
        """)
        
        st.markdown("---")
        st.subheader("ğŸ¤– ì‚¬ìš© ëª¨ë¸")
        st.markdown("""
        - **FinBERT**: BERTë¥¼ ê¸ˆìœµ í…ìŠ¤íŠ¸ë¡œ íŒŒì¸íŠœë‹í•œ ìµœì‹  ëª¨ë¸
        - **Transformer Pipeline**: ê³ ì„±ëŠ¥ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„
        - **AI ê°€ì¤‘í‰ê·  ë°©ì‹**: ëª¨ë¸ì˜ ì‹ ë¢°ë„ë¥¼ ê·¸ëŒ€ë¡œ ë°˜ì˜í•˜ì—¬ ë” ì •í™•í•œ ë¶„ì„
        - **ì‚¬ëŒì˜ ê°œì… ìµœì†Œí™”**: ì„ì˜ì˜ ì„ê³„ê°’ ì—†ì´ AIê°€ 100% íŒë‹¨
        - **Word Cloud**: ì„¼í‹°ë¨¼íŠ¸ë³„/ì¢…ëª©ë³„ ì£¼ìš” ë‹¨ì–´ ì‹œê°í™”
        
        ì´ ë°©ì‹ì€ ì „í†µì  ë°©ì‹ì´ë‚˜ ê·œì¹™ ê¸°ë°˜ ë°©ì‹ë³´ë‹¤ í›¨ì”¬ ë†’ì€ ì •í™•ë„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
        """)

if __name__ == "__main__":
    main()
